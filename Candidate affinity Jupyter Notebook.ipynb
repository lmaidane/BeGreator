{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.util import ngrams\n",
    "import os\n",
    "import docx2txt\n",
    "from geopy.geocoders import Nominatim\n",
    "from geotext import GeoText\n",
    "from geopy.distance import great_circle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skills data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cad',\n",
       " 'svn',\n",
       " 'optimization techniques',\n",
       " 'rdbms',\n",
       " 'product management',\n",
       " 'back-end development',\n",
       " 'power pivot',\n",
       " 'php',\n",
       " 'firewall',\n",
       " 'application development',\n",
       " 'elastic',\n",
       " 'adobe illustrator',\n",
       " 'react',\n",
       " 'hpalm',\n",
       " 'pfmea',\n",
       " 'image recognition systems',\n",
       " 'ai',\n",
       " 'machine learning',\n",
       " 'ux',\n",
       " 'ms sql',\n",
       " 'koin',\n",
       " 'gcp',\n",
       " 'tableau',\n",
       " 'neural networks',\n",
       " 'tornado',\n",
       " 'circleci',\n",
       " 'jenkins',\n",
       " 'spring',\n",
       " 'non aws',\n",
       " 'ios',\n",
       " 'scala',\n",
       " 'pl/sql',\n",
       " 'sas',\n",
       " 'zeplin',\n",
       " 'microsoft excel',\n",
       " 'process modelling',\n",
       " 'artifactory',\n",
       " 'supervised and unsupervised',\n",
       " 'matlab',\n",
       " 'modelling',\n",
       " 'functional analysis',\n",
       " 'ant',\n",
       " 'mvp',\n",
       " 'solution design',\n",
       " 'sea',\n",
       " 'vmware',\n",
       " 'perl',\n",
       " 'redshift',\n",
       " 'c#',\n",
       " 'hbase',\n",
       " 'django',\n",
       " 'quantitative analysis',\n",
       " 'saas',\n",
       " 'figma',\n",
       " 'data regression analysis',\n",
       " 'nodejs',\n",
       " 'react js',\n",
       " 'numpy',\n",
       " 'sbt',\n",
       " 'graph theory',\n",
       " 'angularjs',\n",
       " 'itil',\n",
       " 'snowflake',\n",
       " 'prototype design',\n",
       " 'jax-rs',\n",
       " 'abode suite',\n",
       " 'agile',\n",
       " 'html',\n",
       " 'office 365',\n",
       " 'wcf',\n",
       " 'no sql',\n",
       " 'scrum',\n",
       " 'confluence',\n",
       " 'neural network',\n",
       " 'backend development',\n",
       " 'regression',\n",
       " 'data validation',\n",
       " 'flink',\n",
       " 'adobe xd',\n",
       " 'c/c++',\n",
       " 'swagger',\n",
       " 'fortify',\n",
       " 'javascript',\n",
       " 'vue.js',\n",
       " 'jira',\n",
       " 'sabsa',\n",
       " 'app development',\n",
       " 'data warehousing',\n",
       " 'version control',\n",
       " 'xml',\n",
       " 'vsts',\n",
       " 'hibernate',\n",
       " 'ux/ui',\n",
       " 'e-commerce',\n",
       " 'complex modelling',\n",
       " 'mobx',\n",
       " 'graphical editing',\n",
       " 'torch',\n",
       " 'wcag aa',\n",
       " 'analysis',\n",
       " 'information architecture',\n",
       " 'html5',\n",
       " 'bioinformatics',\n",
       " 'gocd',\n",
       " 'mysql',\n",
       " 'wiki',\n",
       " 'ansible',\n",
       " 'enterprise architecture',\n",
       " 'docker',\n",
       " 'fat',\n",
       " 'quality assurance',\n",
       " 'interaction design',\n",
       " 'embedded system',\n",
       " 'drupal',\n",
       " 'pip',\n",
       " 'risk management',\n",
       " 'lambda',\n",
       " 'data infrastructure',\n",
       " 'cism',\n",
       " 'jvm',\n",
       " 'web analytics',\n",
       " 'nlp',\n",
       " 'qlik',\n",
       " 'data visualisations',\n",
       " 'android sdk',\n",
       " 'google cloud platform',\n",
       " 'illustrator',\n",
       " 'typescript',\n",
       " 'optimization technique',\n",
       " 'cloud computing',\n",
       " 'go',\n",
       " 'lightroom',\n",
       " 'tensorflow',\n",
       " 'redux',\n",
       " 'sass',\n",
       " 'stata',\n",
       " 'solidworks',\n",
       " 'arm',\n",
       " 'adobe suite',\n",
       " 'visual composition',\n",
       " 'sqoop',\n",
       " 'informatica',\n",
       " 'omnichannel',\n",
       " 'adobe',\n",
       " 'data cleaning',\n",
       " 'bpmn',\n",
       " 'oee',\n",
       " 'seo',\n",
       " 'hdfs',\n",
       " 'c-sharp',\n",
       " 'data preprocessing',\n",
       " 'athena',\n",
       " 'ms word',\n",
       " 'prince 2',\n",
       " 'pandas',\n",
       " 'abstract',\n",
       " 'scikit learn',\n",
       " 'spring boot',\n",
       " 'css3',\n",
       " 'data analysis',\n",
       " 'image recognition system',\n",
       " '.net',\n",
       " 'c#.net',\n",
       " 'adfs',\n",
       " 'net',\n",
       " 'pyramid',\n",
       " 'flutter',\n",
       " 'dynamo db',\n",
       " 'microsoft word',\n",
       " 'cx',\n",
       " 'node js',\n",
       " 'jest',\n",
       " 'github',\n",
       " 'oracle',\n",
       " 'ionic',\n",
       " 'cqrs',\n",
       " 'digital design',\n",
       " 'aris',\n",
       " 'hadoop',\n",
       " 'mapreduce',\n",
       " 'xpath',\n",
       " 'process validation',\n",
       " 'ir',\n",
       " 'user experience',\n",
       " 'oozie',\n",
       " 'polymer',\n",
       " 'oracle db',\n",
       " 'jhipster',\n",
       " 'solution architecture',\n",
       " 'hyper-v',\n",
       " 'claim management',\n",
       " 'aws',\n",
       " 'elastic search',\n",
       " 'kotlin',\n",
       " 'word',\n",
       " 'artificial intelligence',\n",
       " 'spark',\n",
       " 'ms project',\n",
       " 'google cloud',\n",
       " 'embedded development',\n",
       " 'ui',\n",
       " 'scss',\n",
       " 'html 5',\n",
       " 'azure cloud',\n",
       " 'microsoft office',\n",
       " 'animation design',\n",
       " 'data visualization',\n",
       " 'natural language processing',\n",
       " 'microsoft bot',\n",
       " 'bigquery',\n",
       " 'impala',\n",
       " 'mongo db',\n",
       " 'power query',\n",
       " 'power bi',\n",
       " 'sharepoint',\n",
       " 'r',\n",
       " 'software testing',\n",
       " 'apache hadoop',\n",
       " 'python',\n",
       " 'data analytical',\n",
       " 'pmi',\n",
       " 'business analysis',\n",
       " 'bigtable sql',\n",
       " 'apache poi',\n",
       " 'creo',\n",
       " 'elasticsearch',\n",
       " 'ruby',\n",
       " 'openshift',\n",
       " 'prototyping',\n",
       " 'optimisation technique',\n",
       " 'http',\n",
       " 'powershell',\n",
       " 'problem solving',\n",
       " 'analytical',\n",
       " 'angular js',\n",
       " 'sketch',\n",
       " 'adobe cc',\n",
       " 'tdd',\n",
       " 'mvvm',\n",
       " 'net c#',\n",
       " 'madcap flare',\n",
       " 'scipy',\n",
       " 'video editing',\n",
       " 'unix',\n",
       " 'presto',\n",
       " 'graph databases',\n",
       " 'reactjs',\n",
       " 'visual design',\n",
       " 'optimisation techniques',\n",
       " 'bpm',\n",
       " 'sqs',\n",
       " 'excel',\n",
       " 'mariadb',\n",
       " 'blockchain',\n",
       " 'firewalls',\n",
       " 'business process management',\n",
       " 'soap',\n",
       " 'salesforce',\n",
       " 'css',\n",
       " 'data interpretation',\n",
       " 'lightgbm',\n",
       " 'blueprism',\n",
       " 'c',\n",
       " 'apache beam',\n",
       " 'golang',\n",
       " 'saml2',\n",
       " 'wireframing',\n",
       " 'uml',\n",
       " 'c#net',\n",
       " 'software development',\n",
       " 'sonar',\n",
       " 'xslt',\n",
       " 'image processing',\n",
       " 'azure',\n",
       " 'mesos',\n",
       " 'statistics',\n",
       " 'kafka',\n",
       " 'android studio',\n",
       " 'pytorch',\n",
       " 'jupyter',\n",
       " 'cloud',\n",
       " 'data visualisation',\n",
       " 'bash',\n",
       " 'nosql',\n",
       " 'selenium',\n",
       " 'user interface',\n",
       " 'vba',\n",
       " 'time series modelling',\n",
       " 'bitbucket',\n",
       " 'sql(oracle)',\n",
       " 'probability',\n",
       " 'statistical',\n",
       " 'rust',\n",
       " 'git',\n",
       " 'tomcat',\n",
       " 'troubleshooting',\n",
       " 'crm',\n",
       " 'networks',\n",
       " 'maven',\n",
       " 'conda',\n",
       " 'keras',\n",
       " 'cgp',\n",
       " 'photoshop',\n",
       " 'angular',\n",
       " 'vector',\n",
       " 'powerpoint',\n",
       " 'data warehouse',\n",
       " 'pmbok',\n",
       " 'animation',\n",
       " 'tensor flow',\n",
       " 'rpa',\n",
       " 'hive',\n",
       " 'data extraction',\n",
       " 'nonaws',\n",
       " 'xamarin',\n",
       " 'arduino',\n",
       " 'autosar',\n",
       " 'apache',\n",
       " 'wireshark',\n",
       " 'product design',\n",
       " 'restful',\n",
       " 'database administration',\n",
       " 'flask',\n",
       " 'application integration',\n",
       " 'sql',\n",
       " 'graph database',\n",
       " 'cassandra',\n",
       " 'business intelligence',\n",
       " 'cuda',\n",
       " 'analytics',\n",
       " 'swarn',\n",
       " 'retrofit',\n",
       " 'sparkr',\n",
       " 'cloud architecture',\n",
       " 'devops',\n",
       " 'vue js',\n",
       " 'etl',\n",
       " 'program management',\n",
       " 's3',\n",
       " 'powerbi',\n",
       " 'data engineering',\n",
       " 'spark/hadoop',\n",
       " 'application architecture',\n",
       " 'js',\n",
       " 'keyshot',\n",
       " 'node.js',\n",
       " 'dbms',\n",
       " 'web design',\n",
       " 'cms',\n",
       " 'wire-framing',\n",
       " 'big table sql',\n",
       " 'api',\n",
       " 'digital photography',\n",
       " 'ci/cd',\n",
       " 'computer architecture',\n",
       " 'transfer learning',\n",
       " 'sap',\n",
       " 'glue',\n",
       " 'enterprise/solution architecture',\n",
       " 'eclipse',\n",
       " 'computer vision',\n",
       " 'feature engineering',\n",
       " 'indesign',\n",
       " 'graphic design',\n",
       " 'deployment',\n",
       " 'object oriented design',\n",
       " 'sat',\n",
       " 'numba',\n",
       " 'react.js',\n",
       " 'digital transformation',\n",
       " 'graphql',\n",
       " 'invision',\n",
       " 'wordpress',\n",
       " 'big data',\n",
       " 'data mining',\n",
       " 'linux',\n",
       " 'data lakes',\n",
       " 'visualisations',\n",
       " 'kubernetes',\n",
       " 'bi',\n",
       " 'akka',\n",
       " 'storm',\n",
       " 'visualizations',\n",
       " 'mvc',\n",
       " 'nginx',\n",
       " 'postgres',\n",
       " 'esb',\n",
       " 'dax',\n",
       " 'xgboost',\n",
       " 'joomla',\n",
       " 'digital finance',\n",
       " 'information retrieval',\n",
       " 'dtp',\n",
       " 'data modelling',\n",
       " 'cp',\n",
       " 'iot',\n",
       " 'mongodb',\n",
       " 'data analytics',\n",
       " 'visualisation',\n",
       " 'kano model',\n",
       " 'digital marketing',\n",
       " 'business process',\n",
       " 'android',\n",
       " 'vuejs',\n",
       " 'rest/soap api',\n",
       " 'data visualizations',\n",
       " 'predictive modelling',\n",
       " 'nexus',\n",
       " 'project management',\n",
       " 'lua',\n",
       " 'spss',\n",
       " 'visualization',\n",
       " 'redis',\n",
       " 'ml',\n",
       " 'finance',\n",
       " 'deep learning',\n",
       " 'java',\n",
       " 'web technology',\n",
       " 'rest api',\n",
       " 'rest',\n",
       " 'restapi',\n",
       " 'telecommunication',\n",
       " 'haskell',\n",
       " 'bamboo',\n",
       " 'neo4j',\n",
       " 'c++',\n",
       " 'mining',\n",
       " 'data manipulation',\n",
       " 'ecs',\n",
       " 'data curation',\n",
       " 'predictive analytics',\n",
       " 'swift',\n",
       " 'data vault',\n",
       " 'mip',\n",
       " 'jquery',\n",
       " 'framer',\n",
       " 'iq',\n",
       " 'citrix',\n",
       " 'talend',\n",
       " 'pyspark',\n",
       " 'json',\n",
       " 'node',\n",
       " 'process management',\n",
       " 'dask',\n",
       " 'sagemaker',\n",
       " 'data vizualisation',\n",
       " 'visual basic']"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading skills csv file\n",
    "skill_data=pd.read_csv(\"skills_lower1 - Sheet1.csv\")\n",
    "\n",
    "#Collecting skills\n",
    "skill_list=[]\n",
    "for i in range(2262):\n",
    "    if(skill_data['skill_or_not'][i]==\"skill\"):\n",
    "        skill_list.append(skill_data['essential:'][i])\n",
    "                \n",
    "#Converting skills data into unique list of skills\n",
    "unique_skill_list=set(skill_list)\n",
    "unique_skill_list=list(unique_skill_list)\n",
    "unique_skill_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Languages data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['danish',\n",
       " 'dutch',\n",
       " 'french',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'german',\n",
       " 'haitian creole',\n",
       " 'indonesian',\n",
       " 'malay',\n",
       " 'swahili',\n",
       " 'albanian',\n",
       " 'amharic',\n",
       " 'armenian',\n",
       " 'azerbaijani',\n",
       " 'bengali',\n",
       " 'bulgarian',\n",
       " 'burmese',\n",
       " 'czech',\n",
       " 'dari',\n",
       " 'estonian',\n",
       " 'farsi',\n",
       " 'finnish',\n",
       " 'georgian',\n",
       " 'greek',\n",
       " 'gujarati',\n",
       " 'hausa',\n",
       " 'hebrew',\n",
       " 'hindi',\n",
       " 'hungarian',\n",
       " 'icelandic',\n",
       " 'kazakh',\n",
       " 'khmer',\n",
       " 'kurdish',\n",
       " 'kyrgyz',\n",
       " 'lao',\n",
       " 'latvian',\n",
       " 'lithuanian',\n",
       " 'macedonian',\n",
       " 'mongolian',\n",
       " 'nepali',\n",
       " 'pashto',\n",
       " 'polish',\n",
       " 'russian',\n",
       " 'serbo-croatian',\n",
       " 'sinhala',\n",
       " 'slovak',\n",
       " 'slovenian',\n",
       " 'somali',\n",
       " 'tagalog',\n",
       " 'tajiki',\n",
       " 'tamil',\n",
       " 'telugu',\n",
       " 'thai',\n",
       " 'tibetan',\n",
       " 'turkish',\n",
       " 'turkmen',\n",
       " 'ukranian',\n",
       " 'urdu',\n",
       " 'uzbek',\n",
       " 'vietnamese',\n",
       " 'arabic',\n",
       " 'chinese - cantonese',\n",
       " 'chinese - mandarin',\n",
       " 'japanese',\n",
       " 'korean']"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading languages csv file\n",
    "language_data=pd.read_csv(\"languages.csv\")\n",
    "\n",
    "#Collecting languages and converting to list\n",
    "language_list=language_data['Language']\n",
    "language_list=list(language_list)\n",
    "\n",
    "#All the languages in the list are converted to lower case (normalization)\n",
    "for i in range(len(language_list)):\n",
    "    language_list[i]=language_list[i].lower()\n",
    "language_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the data of different names of the skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the csv file of different namings for the skills\n",
    "diff_naming=pd.read_csv(\"skill_naming1.csv\")\n",
    "\n",
    "#Converted into a dataframe\n",
    "diff_naming_df=pd.DataFrame(diff_naming)\n",
    "\n",
    "#The incorrect naming is stored in wrong \n",
    "wrong=diff_naming_df['wrong']\n",
    "\n",
    "#The proper naming is stored in correct for the corresponding skills\n",
    "correct=diff_naming_df['correct']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the Job information Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Data Scientist\n"
     ]
    }
   ],
   "source": [
    "#Reading the job information file scrapped from linkedin\n",
    "job_information_data = pd.read_csv(\"Data jobs.csv\")\n",
    "job_information_dataframe=pd.DataFrame(job_information_data)\n",
    "\n",
    "#Can enter a particular row for the corresponding job informations \n",
    "single_company_data=job_information_dataframe.iloc[1637]\n",
    "\n",
    "#Job Description\n",
    "job_description_data=single_company_data['Description']\n",
    "\n",
    "#Location of the company\n",
    "company_location=single_company_data['Location']\n",
    "\n",
    "#Industry type\n",
    "industry=single_company_data['Industry']\n",
    "\n",
    "#Seniority level\n",
    "level=single_company_data['Level']\n",
    "\n",
    "#job_title\n",
    "title=single_company_data['Post']\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(data):\n",
    "    \n",
    "    #Removing punctuations from the text\n",
    "    cleaned_data = re.sub(r'[,.;'':@#?!&$()/|]', ' ', data)\n",
    "    \n",
    "    #tokenization of the text\n",
    "    tokenized_data = nltk.word_tokenize(cleaned_data)\n",
    "    \n",
    "    #Removing Stop words\n",
    "    filtered_words = [word for word in tokenized_data if word not in stopwords.words('english')]\n",
    "    \n",
    "    #All the unigram words are converted to lower case\n",
    "    for i in range(len(filtered_words)):\n",
    "        filtered_words[i] = filtered_words[i]. lower()\n",
    "        \n",
    "    final_words=list()   \n",
    "    for i in filtered_words:    \n",
    "        final_words.append(i)\n",
    "        \n",
    "    #Bigram of words\n",
    "    bigram_data=list(nltk.bigrams(tokenized_data))\n",
    "    for i in bigram_data:\n",
    "        test_string=''\n",
    "        test_string=' '.join(i)\n",
    "        final_words.append(test_string)\n",
    "\n",
    "    #Trigram of words\n",
    "    trigram_data=list(nltk.trigrams(tokenized_data))\n",
    "    for i in trigram_data:\n",
    "        test_string=''\n",
    "        test_string=' '.join(i)\n",
    "        final_words.append(test_string)\n",
    "\n",
    "    #Fourgram of words\n",
    "    fourgram_data=list(nltk.ngrams(tokenized_data,4))\n",
    "    for i in fourgram_data:\n",
    "        test_string=''\n",
    "        test_string=' '.join(i)\n",
    "        final_words.append(test_string)\n",
    "    \n",
    "    #All words are converted to lower case\n",
    "    for i in range(len(final_words)):\n",
    "        final_words[i] = final_words[i]. lower()\n",
    "    return final_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding different types of analytics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_types_analytics(final_words):\n",
    "    \n",
    "    #Collects the previous word of \"analytics\" in the list of words\n",
    "    string=''\n",
    "    for i in range(len(final_words)):\n",
    "        if(final_words[i]==\"analytics\"):\n",
    "            string=string+' '+(str(final_words[i-1]))\n",
    "    \n",
    "    #tokenization\n",
    "    text = nltk.word_tokenize(string)\n",
    "                              \n",
    "    #POS_tagging\n",
    "    #Tells for all the words, whether it is verb, noun, adjective, etc\n",
    "    pos_tagged_text=nltk.pos_tag(text)\n",
    "    tagged_words = nltk.ConditionalFreqDist((tag, word) for (word, tag) in pos_tagged_text)\n",
    "    \n",
    "    #Mentioned the types of noun taggings\n",
    "    noun=['NN','NN$','NN$-HL','NN$-TL','NN-HL','NN-NC','NN-TL','NN-TL-HL','NNS','NNS$','NNS$-HL','NNS$-TL','NNS-HL','NNS-TL','NNS-TL-HL']\n",
    "    \n",
    "    #Collects the previous words of 'analytics' which are noun\n",
    "    final_analytics=[]\n",
    "    for i in range(len(noun)):\n",
    "        for key in tagged_words[noun[i]].keys():\n",
    "            final_analytics.append(key)\n",
    "    \n",
    "    #Appending those noun words like 'data', 'predictive' with 'analytics' ==> 'data analytics', 'predictive analytics'\n",
    "    for i in range(len(final_analytics)):\n",
    "        final_analytics[i]=str(final_analytics[i])+' '+\"analytics\"\n",
    "    return final_analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting languages from a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "def languages(final_words):\n",
    "    #from the list of words, collects the languages\n",
    "    language=[]\n",
    "    for i in range(len(final_words)):\n",
    "        for j in range(len(language_list)):\n",
    "            if(final_words[i]==language_list[j]):\n",
    "                language.append(language_list[j])\n",
    "                \n",
    "    #converting it into unique list\n",
    "    language=set(language)\n",
    "    language=list(language)\n",
    "    #if(len(language)==0):\n",
    "    #    return \"No languages mentioned\"\n",
    "    #else:\n",
    "    return language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding difference between R language and R&D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffbet_Rlang_RndD(final_words):\n",
    "    r_count=0\n",
    "    rd_count=0\n",
    "    for i in range(len(final_words)):\n",
    "        if(final_words[i]==\"r\"):\n",
    "            r_count=r_count+1\n",
    "            if(i==len(final_words)-1):\n",
    "                break;\n",
    "            elif(final_words[i+1]=='d'):\n",
    "                rd_count=rd_count+1\n",
    "    if(rd_count>0):\n",
    "        if(r_count==rd_count):\n",
    "            final_words.remove(\"r\")\n",
    "    return final_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting list of skills from the list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_skill_list(concluded_words,unique_skill_list):\n",
    "    matching_skills=[]\n",
    "    for i in range(len(concluded_words)):\n",
    "        for j in range(len(unique_skill_list)):\n",
    "            if(concluded_words[i]==unique_skill_list[j]):\n",
    "                matching_skills.append(concluded_words[i])\n",
    "    \n",
    "    matching_skills=set(matching_skills)\n",
    "    matching_skills=list(matching_skills)\n",
    "    return matching_skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the incorrectly mentioned skill and appending the skill list with correct name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_wrong_namings(matching_skills,wrong,correct):\n",
    "    for i in range(len(matching_skills)):\n",
    "        for j in range(len(wrong)):\n",
    "            if(matching_skills[i]==wrong[j]):\n",
    "                matching_skills.remove(wrong[j])\n",
    "                matching_skills.append(correct[j])\n",
    "    \n",
    "    matching_skills=set(matching_skills)\n",
    "    matching_skills=list(matching_skills)\n",
    "    return matching_skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding difference between 'analytics' and different types of analytics like 'data analytics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_skills(matching_skills,corrected_skills,final_analytics):\n",
    "    diff_analytics_count=0\n",
    "    analytics_count=0\n",
    "    for i in range(len(matching_skills)):\n",
    "        if(matching_skills[i]==\"analytics\"):\n",
    "            analytics_count=analytics_count+1\n",
    "        for j in range(len(final_analytics)):\n",
    "            if(matching_skills[i]==final_analytics[j]):\n",
    "                diff_analytics_count=diff_analytics_count+1\n",
    "    if(diff_analytics_count>0):\n",
    "        if(analytics_count==diff_analytics_count):\n",
    "            corrected_skills.remove(\"analytics\")\n",
    "    return corrected_skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concluding informations from job data by calling the above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "#calling the above functions\n",
    "words_job_description=processing(job_description_data)\n",
    "\n",
    "final_analytics_jd=diff_types_analytics(words_job_description)    \n",
    "final_languages_jd=languages(words_job_description)\n",
    "concluded_words_jd=diffbet_Rlang_RndD(words_job_description)\n",
    "\n",
    "matching_skills_jd=matching_skill_list(concluded_words_jd,unique_skill_list)\n",
    "corrected_skills_jd=remove_wrong_namings(matching_skills_jd,wrong,correct)\n",
    "processed_skills_jd=processing_skills(matching_skills_jd,corrected_skills_jd,final_analytics_jd)\n",
    "company_score=3\n",
    "company_score=company_score+len(final_languages_jd)\n",
    "company_score=company_score+len(processed_skills_jd)\n",
    "print(company_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Industry Type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading industries names file\n",
    "names_data=pd.read_csv(\"industries1.csv\")\n",
    "names_dataframe=pd.DataFrame(names_data)\n",
    "one=names_dataframe['one']\n",
    "two=names_dataframe['two']\n",
    "three=names_dataframe['three']\n",
    "four=names_dataframe['four']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Financial    Services Insurance']\n"
     ]
    }
   ],
   "source": [
    "#making changes in the words which are wrongly displayed\n",
    "#eg.: SoftwareStaffingRecruiting => Software Staffing Recruting\n",
    "ind=[]\n",
    "\n",
    "string=''\n",
    "for j in industry:\n",
    "    if(j==j.lower()):\n",
    "        string=string+j\n",
    "    if(j==j.upper()):\n",
    "        string = string+\" \"+j\n",
    "ind.append(string)\n",
    "\n",
    "for i in range(len(ind)):\n",
    "    if(\"& &\" in ind[i]):\n",
    "        ind[i]=ind[i].replace(\" & \",' ')\n",
    "    if(\", ,\" in ind[i]):\n",
    "        ind[i]=ind[i].replace(\", ,\",' ')\n",
    "    if(\"/\" in ind[i]):\n",
    "        ind[i]=ind[i].replace(\"/\",' ')\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization        \n",
    "for i in range(len(ind)):\n",
    "    test=nltk.word_tokenize(ind[i])\n",
    "\n",
    "    #finds the industry type of the company    \n",
    "    if(len(test)==1):\n",
    "        for l in range(len(one)):\n",
    "            if(test[0]==one[l]):\n",
    "                found_industry=str(test[0]).lower()\n",
    "\n",
    "    elif(len(test)==2):\n",
    "        for l in range(len(one)):\n",
    "            if(test[0]==one[l] and test[1]==two[l]):\n",
    "                found_industry=str(test[0]+' '+test[1]).lower()\n",
    "            elif(test[1]==one[l] and two[l]==' '):\n",
    "                found_industry=str(test[1]).lower()\n",
    "\n",
    "    elif(len(test)==3):\n",
    "        for l in range(len(one)):\n",
    "            if(test[0]==one[l] and test[1]==two[l] and test[2]==three[l]):\n",
    "                found_industry=str(test[0]+' '+test[1]+' '+test[2]).lower()\n",
    "            elif(test[1]==one[l] and test[2]==two[l]):\n",
    "                found_industry=str(test[1]+' '+test[2]).lower()\n",
    "            elif(test[2]==one[l]):\n",
    "                found_industry=str(test[2]).lower()\n",
    "\n",
    "    elif(len(test)==0):\n",
    "        continue;\n",
    "\n",
    "    else:\n",
    "        ind1=[]\n",
    "        for j in range(len(test),len(test)-4,-1):\n",
    "            ind1.append(test[j-1])\n",
    "        ind1=ind1[::-1]\n",
    "        for l in range(len(one)):\n",
    "            if(ind1[0]==one[l] and ind1[1]==two[l] and ind1[2]==three[l] and ind1[3]==four[l]):\n",
    "                found_industry=str(ind1[0]+' '+ind1[1]+' '+ind1[2]+' '+ind1[3]).lower()\n",
    "            elif(ind1[1]==one[l] and ind1[2]==two[l] and ind1[3]==three[l]):\n",
    "                found_industry=str(ind1[1]+' '+ind1[2]+' '+ind1[3]).lower()\n",
    "            elif(ind1[2]==one[l] and ind1[3]==two[l]):\n",
    "                found_industry=str(ind1[2]+' '+ind1[3]).lower()\n",
    "            elif(ind1[3]==one[l]):\n",
    "                found_industry=str(ind1[3]).lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outputting informations from the resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID                                                     1.9976e+09\n",
      "Date                                                       18-08-2020\n",
      "Company Name                                                   Hiscox\n",
      "Post                                              Lead Data Scientist\n",
      "Location                              London, England, United Kingdom\n",
      "No.of Applicants                                                   25\n",
      "Description         Job Description  About the Group Claims Analyt...\n",
      "Level                                                  Not Applicable\n",
      "Type                                                        Full-time\n",
      "Function                                                        Other\n",
      "Industry                                  Financial ServicesInsurance\n",
      "Link                                                                 \n",
      "Review                                                               \n",
      "Name: 1637, dtype: object\n",
      "\n",
      "Required languages:\n",
      "[]\n",
      "\n",
      "Required skills:\n",
      "['statistics', 'python', 'bi', 'problem solving', 'data analytics', 'go', 'business intelligence', 'machine learning', 'analytics', 'cloud', 'azure', 'google cloud', 'r', 'data visualization', 'sql']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['manila']\n",
      "Candidate location: manila\n",
      "Distance in km:\n",
      "2020_CV_Ronn_Kevin_Santos.docx : 10735.678852673145\n",
      "0\n",
      "[0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "2020_CV_Ronn_Kevin_Santos.docx : []\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1]\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Aaditya_CV.docx : 5478.478415221937\n",
      "0\n",
      "[1, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Aaditya_CV.docx : []\n",
      "0\n",
      "[1, 0]\n",
      "0\n",
      "[1, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1]\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Abdelrahman-CV-N.docx : 5478.478415221937\n",
      "0\n",
      "[1, 1, 0]\n",
      "Languages known : ['arabic']\n",
      "Matching languages : \n",
      "Abdelrahman-CV-N.docx : []\n",
      "0\n",
      "[1, 1, 0]\n",
      "0\n",
      "[1, 1, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1]\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Abdullah_Alattar_2020.docx : 5478.478415221937\n",
      "0\n",
      "[1, 1, 1, 0]\n",
      "Languages known : ['arabic']\n",
      "Matching languages : \n",
      "Abdullah_Alattar_2020.docx : []\n",
      "0\n",
      "[1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['abu dhabi']\n",
      "Candidate location: abu dhabi\n",
      "Distance in km:\n",
      "Abukersh_Jun2020.docx : 5472.345189615449\n",
      "0\n",
      "[1, 1, 1, 1, 0]\n",
      "Languages known : ['arabic', 'italian']\n",
      "Matching languages : \n",
      "Abukersh_Jun2020.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 0]\n",
      "Experience level : 0\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "AdityaM.docx : 5478.478415221937\n",
      "0\n",
      "[1, 1, 1, 1, 1, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "AdityaM.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Afra Yaqoob CV.docx : 5478.478415221937\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Afra Yaqoob CV.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Agnel Mamachan CV & Cover Letter.docx : 5478.478415221937\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Agnel Mamachan CV & Cover Letter.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Experience level : 2\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['tripoli']\n",
      "Candidate location: tripoli\n",
      "Distance in km:\n",
      "Ahmed El Chafei Resume.docx : 2333.314074724882\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Languages known : ['french', 'arabic', 'spanish', 'german', 'dutch', 'italian']\n",
      "Matching languages : \n",
      "Ahmed El Chafei Resume.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['abu dhabi']\n",
      "Candidate location: abu dhabi\n",
      "Distance in km:\n",
      "Ahmed Hassan-CV-Resume-August 2020.docx : 5472.345189615449\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Languages known : ['arabic']\n",
      "Matching languages : \n",
      "Ahmed Hassan-CV-Resume-August 2020.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['karachi']\n",
      "Candidate location: karachi\n",
      "Distance in km:\n",
      "Ahmed Nurullah_BI and Data Lead.docx : 6298.164499583673\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Ahmed Nurullah_BI and Data Lead.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Experience level : 11\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Ahmed_Abdelkader_CV-2.docx : 5478.478415221937\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Languages known : ['arabic']\n",
      "Matching languages : \n",
      "Ahmed_Abdelkader_CV-2.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['indianapolis']\n",
      "Candidate location: indianapolis\n",
      "Distance in km:\n",
      "Aizaz CV 2.01 (4).docx : 6420.193387009308\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Aizaz CV 2.01 (4).docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]\n",
      "\n",
      "\n",
      "['chennai']\n",
      "Candidate location: chennai\n",
      "Distance in km:\n",
      "ajmal_resume.docx : 8211.97733499229\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0]\n",
      "Languages known : ['hindi', 'arabic']\n",
      "Matching languages : \n",
      "ajmal_resume.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0]\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1]\n",
      "Experience level : 12\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2]\n",
      "\n",
      "\n",
      "['mumbai']\n",
      "Candidate location: mumbai\n",
      "Distance in km:\n",
      "Alia_cv_final.docx : 7200.25174889281\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Alia_cv_final.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0]\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1]\n",
      "Experience level : 18\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2]\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Alma-Resume.docx : 5478.478415221937\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 0]\n",
      "Languages known : ['tamil']\n",
      "Matching languages : \n",
      "Alma-Resume.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 0]\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2]\n",
      "\n",
      "\n",
      "['istanbul']\n",
      "Candidate location: istanbul\n",
      "Distance in km:\n",
      "Amine CV-9.docx : 2499.7988198539456\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0]\n",
      "Languages known : ['turkish', 'french', 'spanish', 'arabic']\n",
      "Matching languages : \n",
      "Amine CV-9.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1]\n",
      "\n",
      "\n",
      "['madrid']\n",
      "Candidate location: madrid\n",
      "Distance in km:\n",
      "Antonio Bastidas_Resume_Aug20.docx : 1263.414718393201\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Antonio Bastidas_Resume_Aug20.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 0]\n",
      "Experience level : 5\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1]\n",
      "\n",
      "\n",
      "['hong kong']\n",
      "Candidate location: hong kong\n",
      "Distance in km:\n",
      "Ashley_Choy_CV.docx : 9626.277381457214\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Ashley_Choy_CV.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1]\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Atif_Ahmad_CV.docx : 5478.478415221937\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Atif_Ahmad_CV.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 0]\n",
      "Experience level : 20\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['philadelphia']\n",
      "Candidate location: philadelphia\n",
      "Distance in km:\n",
      "Ayesha Cv -.docx : 5699.690886663006\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 0]\n",
      "Languages known : ['urdu', 'arabic']\n",
      "Matching languages : \n",
      "Ayesha Cv -.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['london']\n",
      "Candidate location: london\n",
      "Distance in km:\n",
      "Bachir Barry Data Science CV.docx : 0.0\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1]\n",
      "Languages known : ['french']\n",
      "Matching languages : \n",
      "Bachir Barry Data Science CV.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atlanta']\n",
      "Candidate location: atlanta\n",
      "Distance in km:\n",
      "Balgopal_Sabat CV.docx : 6770.1074696358255\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 0]\n",
      "Languages known : ['hindi']\n",
      "Matching languages : \n",
      "Balgopal_Sabat CV.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1]\n",
      "\n",
      "\n",
      "['kano']\n",
      "Candidate location: kano\n",
      "Distance in km:\n",
      "Bamidele Olanrewaju Ajayi-converted.docx : 259.0420608764735\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Bamidele Olanrewaju Ajayi-converted.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1]\n",
      "\n",
      "\n",
      "['miami']\n",
      "Candidate location: miami\n",
      "Distance in km:\n",
      "Beatriz Manzano CV.docx : 7126.016062776013\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 0]\n",
      "Languages known : ['spanish']\n",
      "Matching languages : \n",
      "Beatriz Manzano CV.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 0]\n",
      "Experience level : 12\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1]\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "BI Developer- Anupam Parti.docx : 5478.478415221937\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "BI Developer- Anupam Parti.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 0]\n",
      "Experience level : 10\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Bushra's Resume.docx : 5478.478415221937\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 0]\n",
      "Languages known : ['hindi', 'urdu']\n",
      "Matching languages : \n",
      "Bushra's Resume.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 0]\n",
      "Experience level : 5\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['hyderabad']\n",
      "Candidate location: hyderabad\n",
      "Distance in km:\n",
      "CV - DA.docx : 7719.7640521729845\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "CV - DA.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['delhi']\n",
      "Candidate location: delhi\n",
      "Distance in km:\n",
      "CV - Shalaka Kumar (1).docx : 6709.121972691988\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 0]\n",
      "Languages known : ['hindi', 'french', 'urdu']\n",
      "Matching languages : \n",
      "CV - Shalaka Kumar (1).docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 0]\n",
      "Experience level : 2\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['saint petersburg']\n",
      "Candidate location: saint petersburg\n",
      "Distance in km:\n",
      "CV-2020 Mohammed Al Balushi.docx : 2091.23140059856\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Languages known : ['arabic', 'russian']\n",
      "Matching languages : \n",
      "CV-2020 Mohammed Al Balushi.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['davao']\n",
      "Candidate location: davao\n",
      "Distance in km:\n",
      "CV-John-Richard-Gonzales-n.docx : 11713.00331724515\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "CV-John-Richard-Gonzales-n.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['cairo']\n",
      "Candidate location: cairo\n",
      "Distance in km:\n",
      "CV-Mohamed Salem.docx : 3511.391510253383\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Languages known : ['arabic', 'german']\n",
      "Matching languages : \n",
      "CV-Mohamed Salem.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['lahore']\n",
      "Candidate location: lahore\n",
      "Distance in km:\n",
      "CV_Ammara1.docx : 6282.352078939211\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "CV_Ammara1.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Experience level : 10\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['london']\n",
      "Candidate location: london\n",
      "Distance in km:\n",
      "CV_Mohamed Anvergani_4.docx : 0.0\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "CV_Mohamed Anvergani_4.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "CV_Omar_Daoudi_.docx : 5478.478415221937\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0]\n",
      "Languages known : ['arabic']\n",
      "Matching languages : \n",
      "CV_Omar_Daoudi_.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1]\n",
      "\n",
      "\n",
      "['mysore']\n",
      "Candidate location: mysore\n",
      "Distance in km:\n",
      "CV_Ranimaria.docx : 8027.285349716462\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "CV_Ranimaria.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0]\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['enterprise']\n",
      "Candidate location: enterprise\n",
      "Distance in km:\n",
      "Dheemantha Wijesinghe - CV.docx : 7059.359483858228\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Dheemantha Wijesinghe - CV.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 0]\n",
      "Experience level : 3\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1]\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "DIALA ALMALIK CV.docx : 5478.478415221937\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0]\n",
      "Languages known : ['arabic']\n",
      "Matching languages : \n",
      "DIALA ALMALIK CV.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1]\n",
      "\n",
      "\n",
      "['mumbai']\n",
      "Candidate location: mumbai\n",
      "Distance in km:\n",
      "DS-2008.docx : 7200.25174889281\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 0]\n",
      "Languages known : ['hindi']\n",
      "Matching languages : \n",
      "DS-2008.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 0]\n",
      "Experience level : 6\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1]\n",
      "\n",
      "\n",
      "['paris']\n",
      "Candidate location: paris\n",
      "Distance in km:\n",
      "EA-CV_Sameh_BenFredj_2020.docx : 343.5072691492576\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 0]\n",
      "Languages known : ['french', 'spanish', 'arabic']\n",
      "Matching languages : \n",
      "EA-CV_Sameh_BenFredj_2020.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 0]\n",
      "Experience level : 6\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['moscow']\n",
      "Candidate location: moscow\n",
      "Distance in km:\n",
      "EA-Resume Anton Dimov.docx : 2500.5982675695764\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 0]\n",
      "Languages known : ['russian']\n",
      "Matching languages : \n",
      "EA-Resume Anton Dimov.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 0]\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2]\n",
      "\n",
      "\n",
      "['san francisco']\n",
      "Candidate location: san francisco\n",
      "Distance in km:\n",
      "Geoffrey Brown.docx : 8616.093762050956\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Geoffrey Brown.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 0]\n",
      "Experience level : 0\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1]\n",
      "\n",
      "\n",
      "['paris']\n",
      "Candidate location: paris\n",
      "Distance in km:\n",
      "LyanneGibson.docx : 343.5072691492576\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 0]\n",
      "Languages known : ['french']\n",
      "Matching languages : \n",
      "LyanneGibson.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1]\n",
      "\n",
      "\n",
      "['jaipur']\n",
      "Candidate location: jaipur\n",
      "Distance in km:\n",
      "MallikaCV (1).docx : 6751.861567545736\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "MallikaCV (1).docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1]\n",
      "\n",
      "\n",
      "['mumbai']\n",
      "Candidate location: mumbai\n",
      "Distance in km:\n",
      "Mandrekar_Isha.docx : 7200.25174889281\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Mandrekar_Isha.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 0]\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2]\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Matt McCarthy - CV.docx : 5478.478415221937\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Matt McCarthy - CV.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 0]\n",
      "Experience level : 0\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1]\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "MhdAlaa-CV-Updated-2.docx : 5478.478415221937\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "MhdAlaa-CV-Updated-2.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 0]\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1]\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Reeka Hazarika - Resume.docx : 5478.478415221937\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0]\n",
      "Languages known : ['hindi']\n",
      "Matching languages : \n",
      "Reeka Hazarika - Resume.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0]\n",
      "Experience level : 9\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lahore']\n",
      "Candidate location: lahore\n",
      "Distance in km:\n",
      "Resume Sajjad Tahir Nov 2019.docx : 6282.352078939211\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 0]\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Resume Sajjad Tahir Nov 2019.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 0]\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 0]\n",
      "Experience level : 9\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "['hyderabad']\n",
      "Candidate location: hyderabad\n",
      "Distance in km:\n",
      "Shireen-CV-2020.docx : 7719.7640521729845\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 0]\n",
      "Languages known : ['hindi', 'arabic', 'telugu']\n",
      "Matching languages : \n",
      "Shireen-CV-2020.docx : []\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 0]\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1]\n",
      "Experience level : 4\n",
      "level matches\n",
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2]\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2]\n",
      "['industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'insurance', 'insurance', 'insurance', 'insurance', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'insurance', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'insurance', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'insurance', 'industry not found', 'industry not found', 'industry not found', 'insurance', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'insurance']\n",
      "['manila 10735.678852673145', 'dubai 5478.478415221937', 'dubai 5478.478415221937', 'dubai 5478.478415221937', 'abu dhabi 5472.345189615449', 'dubai 5478.478415221937', 'dubai 5478.478415221937', 'dubai 5478.478415221937', 'tripoli 2333.314074724882', 'abu dhabi 5472.345189615449', 'karachi 6298.164499583673', 'dubai 5478.478415221937', 'indianapolis 6420.193387009308', 'chennai 8211.97733499229', 'mumbai 7200.25174889281', 'dubai 5478.478415221937', 'istanbul 2499.7988198539456', 'madrid 1263.414718393201', 'hong kong 9626.277381457214', 'dubai 5478.478415221937', 'philadelphia 5699.690886663006', 'london 0.0', 'atlanta 6770.1074696358255', 'kano 259.0420608764735', 'miami 7126.016062776013', 'dubai 5478.478415221937', 'dubai 5478.478415221937', 'hyderabad 7719.7640521729845', 'delhi 6709.121972691988', 'saint petersburg 2091.23140059856', 'davao 11713.00331724515', 'cairo 3511.391510253383', 'lahore 6282.352078939211', 'london 0.0', 'dubai 5478.478415221937', 'mysore 8027.285349716462', 'enterprise 7059.359483858228', 'dubai 5478.478415221937', 'mumbai 7200.25174889281', 'paris 343.5072691492576', 'moscow 2500.5982675695764', 'san francisco 8616.093762050956', 'paris 343.5072691492576', 'jaipur 6751.861567545736', 'mumbai 7200.25174889281', 'dubai 5478.478415221937', 'dubai 5478.478415221937', 'dubai 5478.478415221937', 'lahore 6282.352078939211', 'hyderabad 7719.7640521729845']\n",
      "['none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none']\n",
      "['level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches']\n"
     ]
    }
   ],
   "source": [
    "#skills and languages are collected from the job description\n",
    "print(single_company_data)\n",
    "print(\"\\nRequired languages:\")\n",
    "print(final_languages_jd)\n",
    "print(\"\\nRequired skills:\")\n",
    "print(processed_skills_jd)\n",
    "print(\"\\n\")\n",
    "\n",
    "score=[]\n",
    "industries3=[]\n",
    "languages3=[]\n",
    "locations3=[]\n",
    "years3=[]\n",
    "candidate_skills=[]\n",
    "candidate={}\n",
    "a,b,c,p,z=0,0,0,0,0\n",
    "name=[]\n",
    "\n",
    "cities_data=pd.read_csv(\"worldcities.csv\")\n",
    "cities=cities_data['city_ascii']\n",
    "for i in range(len(cities)):\n",
    "    cities[i]=cities[i].lower()\n",
    "#print(cities)\n",
    "\n",
    "#Reading all the resumes from the 'resumes' folder\n",
    "entries = os.listdir('resumes')\n",
    "\n",
    "#for loop for each resume\n",
    "for entry in entries:\n",
    "    \n",
    "    #converts docs file to text\n",
    "    resume_data = docx2txt.process(entry)\n",
    "    \n",
    "    #name of the candidate is appended in the list 'name'\n",
    "    name.append(entry)\n",
    "    \n",
    "    #calling the above functions\n",
    "    words_resume=processing(resume_data)\n",
    "    \n",
    "    final_analytics_resume=diff_types_analytics(words_resume)\n",
    "    final_languages_resume=languages(words_resume)\n",
    "    concluded_words_resume=diffbet_Rlang_RndD(words_resume)        \n",
    "    \n",
    "    matching_skills_resume=matching_skill_list(concluded_words_resume,unique_skill_list)\n",
    "    corrected_skills_resume=remove_wrong_namings(matching_skills_resume,wrong,correct)\n",
    "    processed_skills_resume=processing_skills(matching_skills_resume,corrected_skills_resume,final_analytics_resume)\n",
    "    \n",
    "    #skills are collected from the resume\n",
    "    candidate_skills.append(processed_skills_resume)\n",
    "    candidate[name[a]]=processed_skills_resume\n",
    "    a=a+1\n",
    "    \n",
    "    places2=[]\n",
    "    #location of the candidate\n",
    "    for i in range(len(cities)):\n",
    "        for j in range(len(words_resume)):\n",
    "            if(cities[i]==words_resume[j]):\n",
    "                places2.append(words_resume[j])\n",
    "                print(places2)\n",
    "                if(len(places2)==0):\n",
    "                    print(\"goto\")\n",
    "                    continue;\n",
    "                else:\n",
    "                    break;\n",
    "                break;\n",
    "            else: \n",
    "                continue; \n",
    "            break;\n",
    "        else: \n",
    "            continue; \n",
    "        break;\n",
    "    candidate_location=places2[0]\n",
    "    candidate_location=str(candidate_location)\n",
    "    print(\"Candidate location:\",candidate_location)\n",
    "    \n",
    "    places=[]\n",
    "    places.append(company_location)\n",
    "    places.append(candidate_location)\n",
    "    latitude=[]\n",
    "    longitude=[]\n",
    "      \n",
    "    #finding the distance between the candidate location and the company's location\n",
    "    geolocator = Nominatim(user_agent=\"http\")\n",
    "    for i in range(len(places)):\n",
    "        locate = geolocator.geocode(places[i])\n",
    "        latitude.append(locate.latitude)\n",
    "        longitude.append(locate.longitude)\n",
    "           \n",
    "    first = (latitude[0], longitude[0])\n",
    "    second = (latitude[1], longitude[1])\n",
    "    print(\"Distance in km:\")\n",
    "    print(name[b],\":\",great_circle(first, second).km)\n",
    "    location_string=candidate_location+' '+str(great_circle(first, second).km)\n",
    "    scores=0\n",
    "    if(int(great_circle(first, second).km)<=50):\n",
    "        scores=scores+1\n",
    "    elif(int(great_circle(first, second).km)>50):\n",
    "        scores=scores\n",
    "    print(scores)\n",
    "    score.append(scores)\n",
    "    print(score)\n",
    "    b=b+1   \n",
    "    locations3.append(location_string)\n",
    "    \n",
    "    #collects the languages known by the candidate\n",
    "    #if(len(final_languages_resume)==0):\n",
    "    #    print(\"No languages mentioned\")\n",
    "    #else:\n",
    "    print(\"Languages known :\",final_languages_resume)    \n",
    "    \n",
    "    #finds the matching languages with the job description and the candidate's resume\n",
    "    matching_languages=[]\n",
    "    for i in range(len(final_languages_jd)):\n",
    "        for j in range(len(final_languages_resume)):\n",
    "            if(final_languages_jd[i]==final_languages_resume[j]):\n",
    "                matching_languages.append(final_languages_jd[i])\n",
    "    print(\"Matching languages : \")\n",
    "    print(name[c],\":\",matching_languages)\n",
    "    \n",
    "    language_string=''\n",
    "    for lang in range(len(matching_languages)):\n",
    "        language_string=language_string+' '+str(matching_languages[lang])\n",
    "    print(len(matching_languages))\n",
    "    score[c]=score[c]+len(matching_languages)\n",
    "    print(score)\n",
    "    c=c+1\n",
    "    if language_string=='':\n",
    "        language_string=\"none\"\n",
    "    languages3.append(language_string)\n",
    "    \n",
    "    #industry type matching\n",
    "    industry_score=0\n",
    "    industri=' '\n",
    "    for i in range(len(words_resume)):\n",
    "        if(words_resume[i]==found_industry):\n",
    "            industry_score=1\n",
    "            industri=found_industry\n",
    "            #print(industri)\n",
    "            \n",
    "    if(industri==' '):\n",
    "        industri=\"industry not found\"\n",
    "        industry_score=0\n",
    "        \n",
    "    if(industry_score==1):\n",
    "        score[z]=score[z]+1\n",
    "    elif(industry_score==0):\n",
    "        score[z]=score[z]\n",
    "    print(industry_score)\n",
    "    print(score)\n",
    "    z=z+1\n",
    "    industries3.append(industri)\n",
    "    \n",
    "    \n",
    "    #level of experience matching\n",
    "    years=[]\n",
    "    for j in range(len(words_resume)):\n",
    "        if(words_resume[j]=='years'):\n",
    "            try:\n",
    "                years.append(int(words_resume[j-1]))\n",
    "            except:\n",
    "                years.append(0)\n",
    "                \n",
    "    years1=[]\n",
    "    \n",
    "    if(len(years)>0):\n",
    "        for y in range(len(years)):\n",
    "            if(years[y]<=20):\n",
    "                years1.append(years[y])\n",
    "        \n",
    "        if(len(years1)>0):           \n",
    "            maxx=years1[0]\n",
    "            for i in range(0, len(years1)):        \n",
    "                if(years1[i] > maxx):    \n",
    "                    maxx = years1[i] \n",
    "            #year = sum(filter(lambda m: isinstance(m, int), years))\n",
    "            year=maxx\n",
    "            #year=int(''.join(list(filter(lambda c: c.isdigit(), year))))\n",
    "            print(\"Experience level :\",year)\n",
    "\n",
    "        else:\n",
    "            year=0\n",
    "            print(\"Experience level : Not mentioned\")\n",
    "    else:\n",
    "        year=0\n",
    "        print(\"Experience level : Not mentioned\")\n",
    "        \n",
    "    \n",
    "    # Job position's needed level        candidate's years of experience  \n",
    "    #-------------------------------------------------------------------\n",
    "    # Not Applicable                =>   greater than or equal to 0\n",
    "    # Entry level or Associate      =>   greater than or equal to 0\n",
    "    # Mid-Senior level              =>   greater than 3\n",
    "    # Executive                     =>   greater than 5\n",
    "    # Director                      =>   greater than 7\n",
    "    \n",
    "    if(type(level)==str):\n",
    "        if(level==\"Not Applicable\"):\n",
    "            if(year>=0):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "\n",
    "        elif(level==\"Entry level\" or level==\"Associate\"):\n",
    "            if(3>year>=0):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "            else:\n",
    "                print(\"level does not match\")\n",
    "                level_score=0\n",
    "\n",
    "        elif(level==\"Mid-Senior level\"):\n",
    "            if(5>=year>=3):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "            else:\n",
    "                print(\"level does not match\")\n",
    "                level_score=0\n",
    "\n",
    "        elif(level==\"Executive\"):\n",
    "            if(7>=year>=5):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "            else:\n",
    "                print(\"level does not match\")  \n",
    "                level_score=0\n",
    "\n",
    "        elif(level==\"Director\"):\n",
    "            if(year>=7):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "            else:\n",
    "                print(\"level does not match\") \n",
    "                level_score=0\n",
    "        #print(\"\\n\")\n",
    "        \n",
    "    elif(type(level)==int):\n",
    "        if(level==' '):\n",
    "            if(year>=0):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "\n",
    "        elif(3>int(level)>=0):\n",
    "            if(3>year>=0):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "            else:\n",
    "                print(\"level does not match\")\n",
    "                level_score=0\n",
    "\n",
    "        elif(5>=int(level)>=3):\n",
    "            if(5>=year>=3):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "            else:\n",
    "                print(\"level does not match\")\n",
    "                level_score=0\n",
    "\n",
    "        elif(7>=int(level)>=5):\n",
    "            if(7>=year>=5):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "            else:\n",
    "                print(\"level does not match\")  \n",
    "                level_score=0\n",
    "\n",
    "        elif(int(level)>=7):\n",
    "            if(year>=7):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "            else:\n",
    "                print(\"level does not match\") \n",
    "                level_score=0\n",
    "                \n",
    "    if(level_score==1):\n",
    "        level_string=\"level matches\"\n",
    "    elif(level_score==0):\n",
    "        level_string=\"level not matches\"       \n",
    "    years3.append(level_string)  \n",
    "    print(level_score)\n",
    "    score[p]=score[p]+level_score\n",
    "    print(score)\n",
    "    p=p+1\n",
    "    print(\"\\n\")\n",
    "print(score)        \n",
    "print(industries3)\n",
    "print(locations3)\n",
    "print(languages3)\n",
    "print(years3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching skills with the job description and the candidate's resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final ranking : \n",
      "\n",
      "2020_CV_Ronn_Kevin_Santos.docx  :  3\n",
      "Aaditya_CV.docx  :  6\n",
      "Abdelrahman-CV-N.docx  :  2\n",
      "Abdullah_Alattar_2020.docx  :  5\n",
      "Abukersh_Jun2020.docx  :  3\n",
      "AdityaM.docx  :  5\n",
      "Afra Yaqoob CV.docx  :  2\n",
      "Agnel Mamachan CV & Cover Letter.docx  :  6\n",
      "Ahmed El Chafei Resume.docx  :  0\n",
      "Ahmed Hassan-CV-Resume-August 2020.docx  :  4\n",
      "Ahmed Nurullah_BI and Data Lead.docx  :  10\n",
      "Ahmed_Abdelkader_CV-2.docx  :  0\n",
      "Aizaz CV 2.01 (4).docx  :  7\n",
      "ajmal_resume.docx  :  3\n",
      "Alia_cv_final.docx  :  1\n",
      "Alma-Resume.docx  :  4\n",
      "Amine CV-9.docx  :  3\n",
      "Antonio Bastidas_Resume_Aug20.docx  :  10\n",
      "Ashley_Choy_CV.docx  :  8\n",
      "Atif_Ahmad_CV.docx  :  9\n",
      "Ayesha Cv -.docx  :  6\n",
      "Bachir Barry Data Science CV.docx  :  7\n",
      "Balgopal_Sabat CV.docx  :  5\n",
      "Bamidele Olanrewaju Ajayi-converted.docx  :  1\n",
      "Beatriz Manzano CV.docx  :  7\n",
      "BI Developer- Anupam Parti.docx  :  6\n",
      "Bushra's Resume.docx  :  4\n",
      "CV - DA.docx  :  8\n",
      "CV - Shalaka Kumar (1).docx  :  2\n",
      "CV-2020 Mohammed Al Balushi.docx  :  0\n",
      "CV-John-Richard-Gonzales-n.docx  :  2\n",
      "CV-Mohamed Salem.docx  :  1\n",
      "CV_Ammara1.docx  :  6\n",
      "CV_Mohamed Anvergani_4.docx  :  5\n",
      "CV_Omar_Daoudi_.docx  :  6\n",
      "CV_Ranimaria.docx  :  4\n",
      "Dheemantha Wijesinghe - CV.docx  :  4\n",
      "DIALA ALMALIK CV.docx  :  4\n",
      "DS-2008.docx  :  4\n",
      "EA-CV_Sameh_BenFredj_2020.docx  :  9\n",
      "EA-Resume Anton Dimov.docx  :  1\n",
      "Geoffrey Brown.docx  :  5\n",
      "LyanneGibson.docx  :  6\n",
      "MallikaCV (1).docx  :  13\n",
      "Mandrekar_Isha.docx  :  6\n",
      "Matt McCarthy - CV.docx  :  8\n",
      "MhdAlaa-CV-Updated-2.docx  :  3\n",
      "Reeka Hazarika - Resume.docx  :  7\n",
      "Resume Sajjad Tahir Nov 2019.docx  :  4\n",
      "Shireen-CV-2020.docx  :  8\n",
      "\n",
      "Matching skills : \n",
      "\n",
      "2020_CV_Ronn_Kevin_Santos.docx  :  {'python', 'sql', 'data analytics'}\n",
      "Aaditya_CV.docx  :  {'python', 'data analytics', 'machine learning', 'azure', 'cloud', 'r'}\n",
      "Abdelrahman-CV-N.docx  :  {'python', 'data analytics'}\n",
      "Abdullah_Alattar_2020.docx  :  {'python', 'problem solving', 'data analytics', 'machine learning', 'data visualization'}\n",
      "Abukersh_Jun2020.docx  :  {'problem solving', 'analytics', 'data analytics'}\n",
      "AdityaM.docx  :  {'python', 'bi', 'data analytics', 'machine learning', 'data visualization'}\n",
      "Afra Yaqoob CV.docx  :  {'python', 'sql'}\n",
      "Agnel Mamachan CV & Cover Letter.docx  :  {'python', 'problem solving', 'data analytics', 'machine learning', 'analytics', 'sql'}\n",
      "Ahmed El Chafei Resume.docx  :  set()\n",
      "Ahmed Hassan-CV-Resume-August 2020.docx  :  {'r', 'problem solving', 'python', 'data analytics'}\n",
      "Ahmed Nurullah_BI and Data Lead.docx  :  {'statistics', 'python', 'bi', 'data analytics', 'go', 'business intelligence', 'azure', 'cloud', 'data visualization', 'sql'}\n",
      "Ahmed_Abdelkader_CV-2.docx  :  set()\n",
      "Aizaz CV 2.01 (4).docx  :  {'statistics', 'machine learning', 'analytics', 'cloud', 'google cloud', 'data visualization', 'sql'}\n",
      "ajmal_resume.docx  :  {'analytics', 'sql', 'data analytics'}\n",
      "Alia_cv_final.docx  :  {'analytics'}\n",
      "Alma-Resume.docx  :  {'python', 'sql', 'data analytics', 'bi'}\n",
      "Amine CV-9.docx  :  {'python', 'data analytics', 'machine learning'}\n",
      "Antonio Bastidas_Resume_Aug20.docx  :  {'statistics', 'python', 'bi', 'data analytics', 'business intelligence', 'machine learning', 'analytics', 'r', 'data visualization', 'sql'}\n",
      "Ashley_Choy_CV.docx  :  {'statistics', 'python', 'bi', 'data analytics', 'machine learning', 'analytics', 'data visualization', 'sql'}\n",
      "Atif_Ahmad_CV.docx  :  {'python', 'bi', 'data analytics', 'business intelligence', 'machine learning', 'analytics', 'r', 'data visualization', 'sql'}\n",
      "Ayesha Cv -.docx  :  {'python', 'machine learning', 'cloud', 'google cloud', 'r', 'sql'}\n",
      "Bachir Barry Data Science CV.docx  :  {'statistics', 'python', 'problem solving', 'data analytics', 'machine learning', 'analytics', 'r'}\n",
      "Balgopal_Sabat CV.docx  :  {'python', 'bi', 'data analytics', 'r', 'sql'}\n",
      "Bamidele Olanrewaju Ajayi-converted.docx  :  {'problem solving'}\n",
      "Beatriz Manzano CV.docx  :  {'statistics', 'bi', 'problem solving', 'data analytics', 'business intelligence', 'analytics', 'data visualization'}\n",
      "BI Developer- Anupam Parti.docx  :  {'python', 'bi', 'data analytics', 'business intelligence', 'data visualization', 'sql'}\n",
      "Bushra's Resume.docx  :  {'analytics', 'python', 'sql', 'machine learning'}\n",
      "CV - DA.docx  :  {'statistics', 'python', 'data analytics', 'business intelligence', 'machine learning', 'analytics', 'data visualization', 'sql'}\n",
      "CV - Shalaka Kumar (1).docx  :  {'r', 'data analytics'}\n",
      "CV-2020 Mohammed Al Balushi.docx  :  set()\n",
      "CV-John-Richard-Gonzales-n.docx  :  {'r', 'data analytics'}\n",
      "CV-Mohamed Salem.docx  :  {'r'}\n",
      "CV_Ammara1.docx  :  {'statistics', 'python', 'data analytics', 'machine learning', 'data visualization', 'sql'}\n",
      "CV_Mohamed Anvergani_4.docx  :  {'data analytics', 'analytics', 'cloud', 'data visualization', 'sql'}\n",
      "CV_Omar_Daoudi_.docx  :  {'statistics', 'python', 'go', 'cloud', 'r', 'sql'}\n",
      "CV_Ranimaria.docx  :  {'r', 'analytics', 'sql', 'data analytics'}\n",
      "Dheemantha Wijesinghe - CV.docx  :  {'statistics', 'analytics', 'problem solving', 'data analytics'}\n",
      "DIALA ALMALIK CV.docx  :  {'r', 'analytics', 'data analytics', 'problem solving'}\n",
      "DS-2008.docx  :  {'python', 'sql', 'data analytics', 'machine learning'}\n",
      "EA-CV_Sameh_BenFredj_2020.docx  :  {'python', 'data analytics', 'machine learning', 'analytics', 'cloud', 'azure', 'r', 'data visualization', 'sql'}\n",
      "EA-Resume Anton Dimov.docx  :  {'data analytics'}\n",
      "Geoffrey Brown.docx  :  {'statistics', 'python', 'data analytics', 'machine learning', 'data visualization'}\n",
      "LyanneGibson.docx  :  {'statistics', 'python', 'data analytics', 'machine learning', 'r', 'sql'}\n",
      "MallikaCV (1).docx  :  {'statistics', 'python', 'bi', 'problem solving', 'data analytics', 'business intelligence', 'machine learning', 'analytics', 'cloud', 'azure', 'r', 'data visualization', 'sql'}\n",
      "Mandrekar_Isha.docx  :  {'statistics', 'python', 'data analytics', 'machine learning', 'data visualization', 'sql'}\n",
      "Matt McCarthy - CV.docx  :  {'statistics', 'python', 'bi', 'data analytics', 'machine learning', 'cloud', 'r', 'sql'}\n",
      "MhdAlaa-CV-Updated-2.docx  :  {'python', 'cloud', 'sql'}\n",
      "Reeka Hazarika - Resume.docx  :  {'statistics', 'python', 'data analytics', 'machine learning', 'r', 'data visualization', 'sql'}\n",
      "Resume Sajjad Tahir Nov 2019.docx  :  {'statistics', 'analytics', 'business intelligence', 'data analytics'}\n",
      "Shireen-CV-2020.docx  :  {'python', 'bi', 'data analytics', 'go', 'business intelligence', 'analytics', 'data visualization', 'sql'}\n",
      "[4, 7, 3, 6, 4, 6, 3, 7, 1, 5, 11, 1, 9, 5, 3, 6, 4, 11, 9, 10, 7, 10, 6, 2, 8, 7, 5, 9, 3, 1, 3, 2, 7, 7, 7, 6, 5, 5, 5, 10, 3, 6, 7, 14, 8, 9, 4, 8, 5, 10]\n"
     ]
    }
   ],
   "source": [
    "final_rank={}\n",
    "matching={}\n",
    "def fun(candidate,comp,st_n):\n",
    "\n",
    "    set1=set(candidate)\n",
    "    set2=set(comp)\n",
    "    \n",
    "    set3=set1.intersection(set2)\n",
    "    \n",
    "    final_rank.update({st_n:len(set3)})\n",
    "\n",
    "    matching.update({st_n:set3})\n",
    "    \n",
    "for i,j in candidate.items():\n",
    "    fun(processed_skills_jd,j,i)\n",
    "     \n",
    "#Final ranking tells the count of the matching skills \n",
    "#print(\"\\nFinal ranking : \" ,final_rank)\n",
    "print(\"Final ranking : \\n\")\n",
    "i=0\n",
    "for key, value in final_rank.items():\n",
    "    print(key, ' : ', value)\n",
    "    score[i]=score[i]+value\n",
    "    i=i+1\n",
    "\n",
    "#Matching skills\n",
    "#print('Matching skills : ' , matching)\n",
    "print('\\nMatching skills : \\n')\n",
    "for key1, value1 in matching.items():\n",
    "    print(key1, ' : ', value1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['python', 'sql', 'data analytics'], ['python', 'data analytics', 'machine learning', 'azure', 'cloud', 'r'], ['python', 'data analytics'], ['python', 'problem solving', 'data analytics', 'machine learning', 'data visualization'], ['problem solving', 'analytics', 'data analytics'], ['python', 'bi', 'data analytics', 'machine learning', 'data visualization'], ['python', 'sql'], ['python', 'problem solving', 'data analytics', 'machine learning', 'analytics', 'sql'], [], ['r', 'problem solving', 'python', 'data analytics'], ['statistics', 'python', 'bi', 'data analytics', 'go', 'business intelligence', 'azure', 'cloud', 'data visualization', 'sql'], [], ['statistics', 'machine learning', 'analytics', 'cloud', 'google cloud', 'data visualization', 'sql'], ['analytics', 'sql', 'data analytics'], ['analytics'], ['python', 'sql', 'data analytics', 'bi'], ['python', 'data analytics', 'machine learning'], ['statistics', 'python', 'bi', 'data analytics', 'business intelligence', 'machine learning', 'analytics', 'r', 'data visualization', 'sql'], ['statistics', 'python', 'bi', 'data analytics', 'machine learning', 'analytics', 'data visualization', 'sql'], ['python', 'bi', 'data analytics', 'business intelligence', 'machine learning', 'analytics', 'r', 'data visualization', 'sql'], ['python', 'machine learning', 'cloud', 'google cloud', 'r', 'sql'], ['statistics', 'python', 'problem solving', 'data analytics', 'machine learning', 'analytics', 'r'], ['python', 'bi', 'data analytics', 'r', 'sql'], ['problem solving'], ['statistics', 'bi', 'problem solving', 'data analytics', 'business intelligence', 'analytics', 'data visualization'], ['python', 'bi', 'data analytics', 'business intelligence', 'data visualization', 'sql'], ['analytics', 'python', 'sql', 'machine learning'], ['statistics', 'python', 'data analytics', 'business intelligence', 'machine learning', 'analytics', 'data visualization', 'sql'], ['r', 'data analytics'], [], ['r', 'data analytics'], ['r'], ['statistics', 'python', 'data analytics', 'machine learning', 'data visualization', 'sql'], ['data analytics', 'analytics', 'cloud', 'data visualization', 'sql'], ['statistics', 'python', 'go', 'cloud', 'r', 'sql'], ['r', 'analytics', 'sql', 'data analytics'], ['statistics', 'analytics', 'problem solving', 'data analytics'], ['r', 'analytics', 'data analytics', 'problem solving'], ['python', 'sql', 'data analytics', 'machine learning'], ['python', 'data analytics', 'machine learning', 'analytics', 'cloud', 'azure', 'r', 'data visualization', 'sql'], ['data analytics'], ['statistics', 'python', 'data analytics', 'machine learning', 'data visualization'], ['statistics', 'python', 'data analytics', 'machine learning', 'r', 'sql'], ['statistics', 'python', 'bi', 'problem solving', 'data analytics', 'business intelligence', 'machine learning', 'analytics', 'cloud', 'azure', 'r', 'data visualization', 'sql'], ['statistics', 'python', 'data analytics', 'machine learning', 'data visualization', 'sql'], ['statistics', 'python', 'bi', 'data analytics', 'machine learning', 'cloud', 'r', 'sql'], ['python', 'cloud', 'sql'], ['statistics', 'python', 'data analytics', 'machine learning', 'r', 'data visualization', 'sql'], ['statistics', 'analytics', 'business intelligence', 'data analytics'], ['python', 'bi', 'data analytics', 'go', 'business intelligence', 'analytics', 'data visualization', 'sql']]\n"
     ]
    }
   ],
   "source": [
    "names1=[]\n",
    "for key1, value1 in matching.items():\n",
    "    names1.append(key1)\n",
    "#print(names1)\n",
    "ski1=[]\n",
    "for key1, value1 in matching.items():\n",
    "    ski1.append(value1)\n",
    "for i in range(len(ski1)):\n",
    "    ski1[i]=list(ski1[i])\n",
    "print(ski1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 11, 11, 10, 10, 10, 10, 9, 9, 9, 9, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 2, 2, 1, 1, 1] ['industry not found', 'industry not found', 'industry not found', 'insurance', 'insurance', 'industry not found', 'industry not found', 'insurance', 'industry not found', 'industry not found', 'industry not found', 'insurance', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'insurance', 'insurance', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'insurance', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'insurance', 'insurance', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found', 'industry not found'] ['jaipur 6751.861567545736', 'madrid 1263.414718393201', 'karachi 6298.164499583673', 'london 0.0', 'hyderabad 7719.7640521729845', 'paris 343.5072691492576', 'dubai 5478.478415221937', 'indianapolis 6420.193387009308', 'hyderabad 7719.7640521729845', 'hong kong 9626.277381457214', 'dubai 5478.478415221937', 'mumbai 7200.25174889281', 'miami 7126.016062776013', 'dubai 5478.478415221937', 'philadelphia 5699.690886663006', 'paris 343.5072691492576', 'london 0.0', 'lahore 6282.352078939211', 'dubai 5478.478415221937', 'dubai 5478.478415221937', 'dubai 5478.478415221937', 'dubai 5478.478415221937', 'mysore 8027.285349716462', 'dubai 5478.478415221937', 'san francisco 8616.093762050956', 'dubai 5478.478415221937', 'dubai 5478.478415221937', 'atlanta 6770.1074696358255', 'chennai 8211.97733499229', 'mumbai 7200.25174889281', 'lahore 6282.352078939211', 'enterprise 7059.359483858228', 'dubai 5478.478415221937', 'dubai 5478.478415221937', 'abu dhabi 5472.345189615449', 'manila 10735.678852673145', 'istanbul 2499.7988198539456', 'dubai 5478.478415221937', 'abu dhabi 5472.345189615449', 'mumbai 7200.25174889281', 'moscow 2500.5982675695764', 'dubai 5478.478415221937', 'dubai 5478.478415221937', 'delhi 6709.121972691988', 'davao 11713.00331724515', 'kano 259.0420608764735', 'cairo 3511.391510253383', 'tripoli 2333.314074724882', 'saint petersburg 2091.23140059856', 'dubai 5478.478415221937'] ['none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none'] ['level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches', 'level matches'] [['statistics', 'python', 'bi', 'problem solving', 'data analytics', 'business intelligence', 'machine learning', 'analytics', 'cloud', 'azure', 'r', 'data visualization', 'sql'], ['statistics', 'python', 'bi', 'data analytics', 'business intelligence', 'machine learning', 'analytics', 'r', 'data visualization', 'sql'], ['statistics', 'python', 'bi', 'data analytics', 'go', 'business intelligence', 'azure', 'cloud', 'data visualization', 'sql'], ['statistics', 'python', 'problem solving', 'data analytics', 'machine learning', 'analytics', 'r'], ['python', 'bi', 'data analytics', 'go', 'business intelligence', 'analytics', 'data visualization', 'sql'], ['python', 'data analytics', 'machine learning', 'analytics', 'cloud', 'azure', 'r', 'data visualization', 'sql'], ['python', 'bi', 'data analytics', 'business intelligence', 'machine learning', 'analytics', 'r', 'data visualization', 'sql'], ['statistics', 'machine learning', 'analytics', 'cloud', 'google cloud', 'data visualization', 'sql'], ['statistics', 'python', 'data analytics', 'business intelligence', 'machine learning', 'analytics', 'data visualization', 'sql'], ['statistics', 'python', 'bi', 'data analytics', 'machine learning', 'analytics', 'data visualization', 'sql'], ['statistics', 'python', 'bi', 'data analytics', 'machine learning', 'cloud', 'r', 'sql'], ['statistics', 'python', 'data analytics', 'machine learning', 'data visualization', 'sql'], ['statistics', 'bi', 'problem solving', 'data analytics', 'business intelligence', 'analytics', 'data visualization'], ['statistics', 'python', 'data analytics', 'machine learning', 'r', 'data visualization', 'sql'], ['python', 'machine learning', 'cloud', 'google cloud', 'r', 'sql'], ['statistics', 'python', 'data analytics', 'machine learning', 'r', 'sql'], ['data analytics', 'analytics', 'cloud', 'data visualization', 'sql'], ['statistics', 'python', 'data analytics', 'machine learning', 'data visualization', 'sql'], ['statistics', 'python', 'go', 'cloud', 'r', 'sql'], ['python', 'problem solving', 'data analytics', 'machine learning', 'analytics', 'sql'], ['python', 'data analytics', 'machine learning', 'azure', 'cloud', 'r'], ['python', 'bi', 'data analytics', 'business intelligence', 'data visualization', 'sql'], ['r', 'analytics', 'sql', 'data analytics'], ['python', 'sql', 'data analytics', 'bi'], ['statistics', 'python', 'data analytics', 'machine learning', 'data visualization'], ['python', 'problem solving', 'data analytics', 'machine learning', 'data visualization'], ['python', 'bi', 'data analytics', 'machine learning', 'data visualization'], ['python', 'bi', 'data analytics', 'r', 'sql'], ['analytics', 'sql', 'data analytics'], ['python', 'sql', 'data analytics', 'machine learning'], ['statistics', 'analytics', 'business intelligence', 'data analytics'], ['statistics', 'analytics', 'problem solving', 'data analytics'], ['r', 'analytics', 'data analytics', 'problem solving'], ['analytics', 'python', 'sql', 'machine learning'], ['r', 'problem solving', 'python', 'data analytics'], ['python', 'sql', 'data analytics'], ['python', 'data analytics', 'machine learning'], ['python', 'cloud', 'sql'], ['problem solving', 'analytics', 'data analytics'], ['analytics'], ['data analytics'], ['python', 'sql'], ['python', 'data analytics'], ['r', 'data analytics'], ['r', 'data analytics'], ['problem solving'], ['r'], [], [], []] ['MallikaCV (1).docx', 'Antonio Bastidas_Resume_Aug20.docx', 'Ahmed Nurullah_BI and Data Lead.docx', 'Bachir Barry Data Science CV.docx', 'Shireen-CV-2020.docx', 'EA-CV_Sameh_BenFredj_2020.docx', 'Atif_Ahmad_CV.docx', 'Aizaz CV 2.01 (4).docx', 'CV - DA.docx', 'Ashley_Choy_CV.docx', 'Matt McCarthy - CV.docx', 'Mandrekar_Isha.docx', 'Beatriz Manzano CV.docx', 'Reeka Hazarika - Resume.docx', 'Ayesha Cv -.docx', 'LyanneGibson.docx', 'CV_Mohamed Anvergani_4.docx', 'CV_Ammara1.docx', 'CV_Omar_Daoudi_.docx', 'Agnel Mamachan CV & Cover Letter.docx', 'Aaditya_CV.docx', 'BI Developer- Anupam Parti.docx', 'CV_Ranimaria.docx', 'Alma-Resume.docx', 'Geoffrey Brown.docx', 'Abdullah_Alattar_2020.docx', 'AdityaM.docx', 'Balgopal_Sabat CV.docx', 'ajmal_resume.docx', 'DS-2008.docx', 'Resume Sajjad Tahir Nov 2019.docx', 'Dheemantha Wijesinghe - CV.docx', 'DIALA ALMALIK CV.docx', \"Bushra's Resume.docx\", 'Ahmed Hassan-CV-Resume-August 2020.docx', '2020_CV_Ronn_Kevin_Santos.docx', 'Amine CV-9.docx', 'MhdAlaa-CV-Updated-2.docx', 'Abukersh_Jun2020.docx', 'Alia_cv_final.docx', 'EA-Resume Anton Dimov.docx', 'Afra Yaqoob CV.docx', 'Abdelrahman-CV-N.docx', 'CV - Shalaka Kumar (1).docx', 'CV-John-Richard-Gonzales-n.docx', 'Bamidele Olanrewaju Ajayi-converted.docx', 'CV-Mohamed Salem.docx', 'Ahmed El Chafei Resume.docx', 'CV-2020 Mohammed Al Balushi.docx', 'Ahmed_Abdelkader_CV-2.docx']\n"
     ]
    }
   ],
   "source": [
    "zipped = list(zip(*sorted(zip(score,industries3,locations3,languages3,years3,ski1,names1))))\n",
    "score10,industries10,locations10,languages10,years10,ski10,names10 = [ list(tuple) for tuple in zipped]\n",
    "\n",
    "score10.reverse()\n",
    "industries10.reverse()\n",
    "locations10.reverse()\n",
    "languages10.reverse()\n",
    "years10.reverse()\n",
    "ski10.reverse()\n",
    "names10.reverse()\n",
    "print(score10,industries10,locations10,languages10,years10,ski10,names10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies2=[]\n",
    "companies2.append(title)\n",
    "companies2.append(1639)\n",
    "companies2.append(found_industry)\n",
    "companies2.append(final_languages_jd)\n",
    "companies2.append(company_location)\n",
    "companies2.append(level)\n",
    "companies2.append(processed_skills_jd)\n",
    "comp_len=len(companies2)\n",
    "for i in range(len(scores2)-comp_len):\n",
    "    companies2.append(' ')\n",
    "#print(companies2)\n",
    "\n",
    "properties2=[]\n",
    "properties2.append(company_score)\n",
    "for i in range(len(scores2)-1):\n",
    "    properties2.append(' ')\n",
    "#print(properties2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes3=pd.DataFrame({'Company':companies2,\n",
    "                      'Property':properties2,\n",
    "                      'Names':names10,\n",
    "                      'Score':score10,\n",
    "                      'Industry':industries10,\n",
    "                      'Language':languages10,\n",
    "                      'Location':locations10,\n",
    "                      'Experience level':years10,\n",
    "                      'Skills':ski10})\n",
    "      \n",
    "#storing in csv file\n",
    "resumes3.to_csv(\"Output3.csv\", mode='a', header=False, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

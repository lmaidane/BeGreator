{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.util import ngrams\n",
    "import os\n",
    "import docx2txt\n",
    "from geopy.geocoders import Nominatim\n",
    "from geotext import GeoText\n",
    "from geopy.distance import great_circle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skills data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cad',\n",
       " 'svn',\n",
       " 'optimization techniques',\n",
       " 'rdbms',\n",
       " 'product management',\n",
       " 'back-end development',\n",
       " 'power pivot',\n",
       " 'php',\n",
       " 'firewall',\n",
       " 'application development',\n",
       " 'elastic',\n",
       " 'adobe illustrator',\n",
       " 'react',\n",
       " 'hpalm',\n",
       " 'pfmea',\n",
       " 'image recognition systems',\n",
       " 'ai',\n",
       " 'machine learning',\n",
       " 'ux',\n",
       " 'ms sql',\n",
       " 'koin',\n",
       " 'gcp',\n",
       " 'tableau',\n",
       " 'neural networks',\n",
       " 'tornado',\n",
       " 'circleci',\n",
       " 'jenkins',\n",
       " 'spring',\n",
       " 'non aws',\n",
       " 'ios',\n",
       " 'scala',\n",
       " 'pl/sql',\n",
       " 'sas',\n",
       " 'zeplin',\n",
       " 'microsoft excel',\n",
       " 'process modelling',\n",
       " 'artifactory',\n",
       " 'supervised and unsupervised',\n",
       " 'matlab',\n",
       " 'modelling',\n",
       " 'functional analysis',\n",
       " 'ant',\n",
       " 'mvp',\n",
       " 'solution design',\n",
       " 'sea',\n",
       " 'vmware',\n",
       " 'perl',\n",
       " 'redshift',\n",
       " 'c#',\n",
       " 'hbase',\n",
       " 'django',\n",
       " 'quantitative analysis',\n",
       " 'saas',\n",
       " 'figma',\n",
       " 'data regression analysis',\n",
       " 'nodejs',\n",
       " 'react js',\n",
       " 'numpy',\n",
       " 'sbt',\n",
       " 'graph theory',\n",
       " 'angularjs',\n",
       " 'itil',\n",
       " 'snowflake',\n",
       " 'prototype design',\n",
       " 'jax-rs',\n",
       " 'abode suite',\n",
       " 'agile',\n",
       " 'html',\n",
       " 'office 365',\n",
       " 'wcf',\n",
       " 'no sql',\n",
       " 'scrum',\n",
       " 'confluence',\n",
       " 'neural network',\n",
       " 'backend development',\n",
       " 'regression',\n",
       " 'data validation',\n",
       " 'flink',\n",
       " 'adobe xd',\n",
       " 'c/c++',\n",
       " 'swagger',\n",
       " 'fortify',\n",
       " 'javascript',\n",
       " 'vue.js',\n",
       " 'jira',\n",
       " 'sabsa',\n",
       " 'app development',\n",
       " 'data warehousing',\n",
       " 'version control',\n",
       " 'xml',\n",
       " 'vsts',\n",
       " 'hibernate',\n",
       " 'ux/ui',\n",
       " 'e-commerce',\n",
       " 'complex modelling',\n",
       " 'mobx',\n",
       " 'graphical editing',\n",
       " 'torch',\n",
       " 'wcag aa',\n",
       " 'analysis',\n",
       " 'information architecture',\n",
       " 'html5',\n",
       " 'bioinformatics',\n",
       " 'gocd',\n",
       " 'mysql',\n",
       " 'wiki',\n",
       " 'ansible',\n",
       " 'enterprise architecture',\n",
       " 'docker',\n",
       " 'fat',\n",
       " 'quality assurance',\n",
       " 'interaction design',\n",
       " 'embedded system',\n",
       " 'drupal',\n",
       " 'pip',\n",
       " 'risk management',\n",
       " 'lambda',\n",
       " 'data infrastructure',\n",
       " 'cism',\n",
       " 'jvm',\n",
       " 'web analytics',\n",
       " 'nlp',\n",
       " 'qlik',\n",
       " 'data visualisations',\n",
       " 'android sdk',\n",
       " 'google cloud platform',\n",
       " 'illustrator',\n",
       " 'typescript',\n",
       " 'optimization technique',\n",
       " 'cloud computing',\n",
       " 'go',\n",
       " 'lightroom',\n",
       " 'tensorflow',\n",
       " 'redux',\n",
       " 'sass',\n",
       " 'stata',\n",
       " 'solidworks',\n",
       " 'arm',\n",
       " 'adobe suite',\n",
       " 'visual composition',\n",
       " 'sqoop',\n",
       " 'informatica',\n",
       " 'omnichannel',\n",
       " 'adobe',\n",
       " 'data cleaning',\n",
       " 'bpmn',\n",
       " 'oee',\n",
       " 'seo',\n",
       " 'hdfs',\n",
       " 'c-sharp',\n",
       " 'data preprocessing',\n",
       " 'athena',\n",
       " 'ms word',\n",
       " 'prince 2',\n",
       " 'pandas',\n",
       " 'abstract',\n",
       " 'scikit learn',\n",
       " 'spring boot',\n",
       " 'css3',\n",
       " 'data analysis',\n",
       " 'image recognition system',\n",
       " '.net',\n",
       " 'c#.net',\n",
       " 'adfs',\n",
       " 'net',\n",
       " 'pyramid',\n",
       " 'flutter',\n",
       " 'dynamo db',\n",
       " 'microsoft word',\n",
       " 'cx',\n",
       " 'node js',\n",
       " 'jest',\n",
       " 'github',\n",
       " 'oracle',\n",
       " 'ionic',\n",
       " 'cqrs',\n",
       " 'digital design',\n",
       " 'aris',\n",
       " 'hadoop',\n",
       " 'mapreduce',\n",
       " 'xpath',\n",
       " 'process validation',\n",
       " 'ir',\n",
       " 'user experience',\n",
       " 'oozie',\n",
       " 'polymer',\n",
       " 'oracle db',\n",
       " 'jhipster',\n",
       " 'solution architecture',\n",
       " 'hyper-v',\n",
       " 'claim management',\n",
       " 'aws',\n",
       " 'elastic search',\n",
       " 'kotlin',\n",
       " 'word',\n",
       " 'artificial intelligence',\n",
       " 'spark',\n",
       " 'ms project',\n",
       " 'google cloud',\n",
       " 'embedded development',\n",
       " 'ui',\n",
       " 'scss',\n",
       " 'html 5',\n",
       " 'azure cloud',\n",
       " 'microsoft office',\n",
       " 'animation design',\n",
       " 'data visualization',\n",
       " 'natural language processing',\n",
       " 'microsoft bot',\n",
       " 'bigquery',\n",
       " 'impala',\n",
       " 'mongo db',\n",
       " 'power query',\n",
       " 'power bi',\n",
       " 'sharepoint',\n",
       " 'r',\n",
       " 'software testing',\n",
       " 'apache hadoop',\n",
       " 'python',\n",
       " 'data analytical',\n",
       " 'pmi',\n",
       " 'business analysis',\n",
       " 'bigtable sql',\n",
       " 'apache poi',\n",
       " 'creo',\n",
       " 'elasticsearch',\n",
       " 'ruby',\n",
       " 'openshift',\n",
       " 'prototyping',\n",
       " 'optimisation technique',\n",
       " 'http',\n",
       " 'powershell',\n",
       " 'problem solving',\n",
       " 'analytical',\n",
       " 'angular js',\n",
       " 'sketch',\n",
       " 'adobe cc',\n",
       " 'tdd',\n",
       " 'mvvm',\n",
       " 'net c#',\n",
       " 'madcap flare',\n",
       " 'scipy',\n",
       " 'video editing',\n",
       " 'unix',\n",
       " 'presto',\n",
       " 'graph databases',\n",
       " 'reactjs',\n",
       " 'visual design',\n",
       " 'optimisation techniques',\n",
       " 'bpm',\n",
       " 'sqs',\n",
       " 'excel',\n",
       " 'mariadb',\n",
       " 'blockchain',\n",
       " 'firewalls',\n",
       " 'business process management',\n",
       " 'soap',\n",
       " 'salesforce',\n",
       " 'css',\n",
       " 'data interpretation',\n",
       " 'lightgbm',\n",
       " 'blueprism',\n",
       " 'c',\n",
       " 'apache beam',\n",
       " 'golang',\n",
       " 'saml2',\n",
       " 'wireframing',\n",
       " 'uml',\n",
       " 'c#net',\n",
       " 'software development',\n",
       " 'sonar',\n",
       " 'xslt',\n",
       " 'image processing',\n",
       " 'azure',\n",
       " 'mesos',\n",
       " 'statistics',\n",
       " 'kafka',\n",
       " 'android studio',\n",
       " 'pytorch',\n",
       " 'jupyter',\n",
       " 'cloud',\n",
       " 'data visualisation',\n",
       " 'bash',\n",
       " 'nosql',\n",
       " 'selenium',\n",
       " 'user interface',\n",
       " 'vba',\n",
       " 'time series modelling',\n",
       " 'bitbucket',\n",
       " 'sql(oracle)',\n",
       " 'probability',\n",
       " 'statistical',\n",
       " 'rust',\n",
       " 'git',\n",
       " 'tomcat',\n",
       " 'troubleshooting',\n",
       " 'crm',\n",
       " 'networks',\n",
       " 'maven',\n",
       " 'conda',\n",
       " 'keras',\n",
       " 'cgp',\n",
       " 'photoshop',\n",
       " 'angular',\n",
       " 'vector',\n",
       " 'powerpoint',\n",
       " 'data warehouse',\n",
       " 'pmbok',\n",
       " 'animation',\n",
       " 'tensor flow',\n",
       " 'rpa',\n",
       " 'hive',\n",
       " 'data extraction',\n",
       " 'nonaws',\n",
       " 'xamarin',\n",
       " 'arduino',\n",
       " 'autosar',\n",
       " 'apache',\n",
       " 'wireshark',\n",
       " 'product design',\n",
       " 'restful',\n",
       " 'database administration',\n",
       " 'flask',\n",
       " 'application integration',\n",
       " 'sql',\n",
       " 'graph database',\n",
       " 'cassandra',\n",
       " 'business intelligence',\n",
       " 'cuda',\n",
       " 'analytics',\n",
       " 'swarn',\n",
       " 'retrofit',\n",
       " 'sparkr',\n",
       " 'cloud architecture',\n",
       " 'devops',\n",
       " 'vue js',\n",
       " 'etl',\n",
       " 'program management',\n",
       " 's3',\n",
       " 'powerbi',\n",
       " 'data engineering',\n",
       " 'spark/hadoop',\n",
       " 'application architecture',\n",
       " 'js',\n",
       " 'keyshot',\n",
       " 'node.js',\n",
       " 'dbms',\n",
       " 'web design',\n",
       " 'cms',\n",
       " 'wire-framing',\n",
       " 'big table sql',\n",
       " 'api',\n",
       " 'digital photography',\n",
       " 'ci/cd',\n",
       " 'computer architecture',\n",
       " 'transfer learning',\n",
       " 'sap',\n",
       " 'glue',\n",
       " 'enterprise/solution architecture',\n",
       " 'eclipse',\n",
       " 'computer vision',\n",
       " 'feature engineering',\n",
       " 'indesign',\n",
       " 'graphic design',\n",
       " 'deployment',\n",
       " 'object oriented design',\n",
       " 'sat',\n",
       " 'numba',\n",
       " 'react.js',\n",
       " 'digital transformation',\n",
       " 'graphql',\n",
       " 'invision',\n",
       " 'wordpress',\n",
       " 'big data',\n",
       " 'data mining',\n",
       " 'linux',\n",
       " 'data lakes',\n",
       " 'visualisations',\n",
       " 'kubernetes',\n",
       " 'bi',\n",
       " 'akka',\n",
       " 'storm',\n",
       " 'visualizations',\n",
       " 'mvc',\n",
       " 'nginx',\n",
       " 'postgres',\n",
       " 'esb',\n",
       " 'dax',\n",
       " 'xgboost',\n",
       " 'joomla',\n",
       " 'digital finance',\n",
       " 'information retrieval',\n",
       " 'dtp',\n",
       " 'data modelling',\n",
       " 'cp',\n",
       " 'iot',\n",
       " 'mongodb',\n",
       " 'data analytics',\n",
       " 'visualisation',\n",
       " 'kano model',\n",
       " 'digital marketing',\n",
       " 'business process',\n",
       " 'android',\n",
       " 'vuejs',\n",
       " 'rest/soap api',\n",
       " 'data visualizations',\n",
       " 'predictive modelling',\n",
       " 'nexus',\n",
       " 'project management',\n",
       " 'lua',\n",
       " 'spss',\n",
       " 'visualization',\n",
       " 'redis',\n",
       " 'ml',\n",
       " 'finance',\n",
       " 'deep learning',\n",
       " 'java',\n",
       " 'web technology',\n",
       " 'rest api',\n",
       " 'rest',\n",
       " 'restapi',\n",
       " 'telecommunication',\n",
       " 'haskell',\n",
       " 'bamboo',\n",
       " 'neo4j',\n",
       " 'c++',\n",
       " 'mining',\n",
       " 'data manipulation',\n",
       " 'ecs',\n",
       " 'data curation',\n",
       " 'predictive analytics',\n",
       " 'swift',\n",
       " 'data vault',\n",
       " 'mip',\n",
       " 'jquery',\n",
       " 'framer',\n",
       " 'iq',\n",
       " 'citrix',\n",
       " 'talend',\n",
       " 'pyspark',\n",
       " 'json',\n",
       " 'node',\n",
       " 'process management',\n",
       " 'dask',\n",
       " 'sagemaker',\n",
       " 'data vizualisation',\n",
       " 'visual basic']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading skills csv file\n",
    "skill_data=pd.read_csv(\"skills_lower1 - Sheet1.csv\")\n",
    "\n",
    "#Collecting skills\n",
    "skill_list=[]\n",
    "for i in range(2262):\n",
    "    if(skill_data['skill_or_not'][i]==\"skill\"):\n",
    "        skill_list.append(skill_data['essential:'][i])\n",
    "                \n",
    "#Converting skills data into unique list of skills\n",
    "unique_skill_list=set(skill_list)\n",
    "unique_skill_list=list(unique_skill_list)\n",
    "unique_skill_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Languages data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['danish',\n",
       " 'dutch',\n",
       " 'french',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'german',\n",
       " 'haitian creole',\n",
       " 'indonesian',\n",
       " 'malay',\n",
       " 'swahili',\n",
       " 'albanian',\n",
       " 'amharic',\n",
       " 'armenian',\n",
       " 'azerbaijani',\n",
       " 'bengali',\n",
       " 'bulgarian',\n",
       " 'burmese',\n",
       " 'czech',\n",
       " 'dari',\n",
       " 'estonian',\n",
       " 'farsi',\n",
       " 'finnish',\n",
       " 'georgian',\n",
       " 'greek',\n",
       " 'gujarati',\n",
       " 'hausa',\n",
       " 'hebrew',\n",
       " 'hindi',\n",
       " 'hungarian',\n",
       " 'icelandic',\n",
       " 'kazakh',\n",
       " 'khmer',\n",
       " 'kurdish',\n",
       " 'kyrgyz',\n",
       " 'lao',\n",
       " 'latvian',\n",
       " 'lithuanian',\n",
       " 'macedonian',\n",
       " 'mongolian',\n",
       " 'nepali',\n",
       " 'pashto',\n",
       " 'polish',\n",
       " 'russian',\n",
       " 'serbo-croatian',\n",
       " 'sinhala',\n",
       " 'slovak',\n",
       " 'slovenian',\n",
       " 'somali',\n",
       " 'tagalog',\n",
       " 'tajiki',\n",
       " 'tamil',\n",
       " 'telugu',\n",
       " 'thai',\n",
       " 'tibetan',\n",
       " 'turkish',\n",
       " 'turkmen',\n",
       " 'ukranian',\n",
       " 'urdu',\n",
       " 'uzbek',\n",
       " 'vietnamese',\n",
       " 'arabic',\n",
       " 'chinese - cantonese',\n",
       " 'chinese - mandarin',\n",
       " 'japanese',\n",
       " 'korean']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading languages csv file\n",
    "language_data=pd.read_csv(\"languages.csv\")\n",
    "\n",
    "#Collecting languages and converting to list\n",
    "language_list=language_data['Language']\n",
    "language_list=list(language_list)\n",
    "\n",
    "#All the languages in the list are converted to lower case (normalization)\n",
    "for i in range(len(language_list)):\n",
    "    language_list[i]=language_list[i].lower()\n",
    "language_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the data of different names of the skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the csv file of different namings for the skills\n",
    "diff_naming=pd.read_csv(\"skill_naming1.csv\")\n",
    "\n",
    "#Converted into a dataframe\n",
    "diff_naming_df=pd.DataFrame(diff_naming)\n",
    "\n",
    "#The incorrect naming is stored in wrong \n",
    "wrong=diff_naming_df['wrong']\n",
    "\n",
    "#The proper naming is stored in correct for the corresponding skills\n",
    "correct=diff_naming_df['correct']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the Job information Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Analyst\n"
     ]
    }
   ],
   "source": [
    "#Reading the job information file scrapped from linkedin\n",
    "job_information_data = pd.read_csv(\"Data jobs.csv\")\n",
    "job_information_dataframe=pd.DataFrame(job_information_data)\n",
    "\n",
    "#Can enter a particular row for the corresponding job informations \n",
    "single_company_data=job_information_dataframe.iloc[1643]\n",
    "\n",
    "#Job Description\n",
    "job_description_data=single_company_data['Description']\n",
    "\n",
    "#Location of the company\n",
    "company_location=single_company_data['Location']\n",
    "\n",
    "#Industry type\n",
    "industry=single_company_data['Industry']\n",
    "\n",
    "#Seniority level\n",
    "level=single_company_data['Level']\n",
    "\n",
    "#job_title\n",
    "title=single_company_data['Post']\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(data):\n",
    "    \n",
    "    #Removing punctuations from the text\n",
    "    cleaned_data = re.sub(r'[,.;'':@#?!&$()/|]', ' ', data)\n",
    "    \n",
    "    #tokenization of the text\n",
    "    tokenized_data = nltk.word_tokenize(cleaned_data)\n",
    "    \n",
    "    #Removing Stop words\n",
    "    filtered_words = [word for word in tokenized_data if word not in stopwords.words('english')]\n",
    "    \n",
    "    #All the unigram words are converted to lower case\n",
    "    for i in range(len(filtered_words)):\n",
    "        filtered_words[i] = filtered_words[i]. lower()\n",
    "        \n",
    "    final_words=list()   \n",
    "    for i in filtered_words:    \n",
    "        final_words.append(i)\n",
    "        \n",
    "    #Bigram of words\n",
    "    bigram_data=list(nltk.bigrams(tokenized_data))\n",
    "    for i in bigram_data:\n",
    "        test_string=''\n",
    "        test_string=' '.join(i)\n",
    "        final_words.append(test_string)\n",
    "\n",
    "    #Trigram of words\n",
    "    trigram_data=list(nltk.trigrams(tokenized_data))\n",
    "    for i in trigram_data:\n",
    "        test_string=''\n",
    "        test_string=' '.join(i)\n",
    "        final_words.append(test_string)\n",
    "\n",
    "    #Fourgram of words\n",
    "    fourgram_data=list(nltk.ngrams(tokenized_data,4))\n",
    "    for i in fourgram_data:\n",
    "        test_string=''\n",
    "        test_string=' '.join(i)\n",
    "        final_words.append(test_string)\n",
    "    \n",
    "    #All words are converted to lower case\n",
    "    for i in range(len(final_words)):\n",
    "        final_words[i] = final_words[i]. lower()\n",
    "    return final_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding different types of analytics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_types_analytics(final_words):\n",
    "    \n",
    "    #Collects the previous word of \"analytics\" in the list of words\n",
    "    string=''\n",
    "    for i in range(len(final_words)):\n",
    "        if(final_words[i]==\"analytics\"):\n",
    "            string=string+' '+(str(final_words[i-1]))\n",
    "    \n",
    "    #tokenization\n",
    "    text = nltk.word_tokenize(string)\n",
    "                              \n",
    "    #POS_tagging\n",
    "    #Tells for all the words, whether it is verb, noun, adjective, etc\n",
    "    pos_tagged_text=nltk.pos_tag(text)\n",
    "    tagged_words = nltk.ConditionalFreqDist((tag, word) for (word, tag) in pos_tagged_text)\n",
    "    \n",
    "    #Mentioned the types of noun taggings\n",
    "    noun=['NN','NN$','NN$-HL','NN$-TL','NN-HL','NN-NC','NN-TL','NN-TL-HL','NNS','NNS$','NNS$-HL','NNS$-TL','NNS-HL','NNS-TL','NNS-TL-HL']\n",
    "    \n",
    "    #Collects the previous words of 'analytics' which are noun\n",
    "    final_analytics=[]\n",
    "    for i in range(len(noun)):\n",
    "        for key in tagged_words[noun[i]].keys():\n",
    "            final_analytics.append(key)\n",
    "    \n",
    "    #Appending those noun words like 'data', 'predictive' with 'analytics' ==> 'data analytics', 'predictive analytics'\n",
    "    for i in range(len(final_analytics)):\n",
    "        final_analytics[i]=str(final_analytics[i])+' '+\"analytics\"\n",
    "    return final_analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting languages from a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def languages(final_words):\n",
    "    #from the list of words, collects the languages\n",
    "    language=[]\n",
    "    for i in range(len(final_words)):\n",
    "        for j in range(len(language_list)):\n",
    "            if(final_words[i]==language_list[j]):\n",
    "                language.append(language_list[j])\n",
    "                \n",
    "    #converting it into unique list\n",
    "    language=set(language)\n",
    "    language=list(language)\n",
    "    #if(len(language)==0):\n",
    "    #    return \"No languages mentioned\"\n",
    "    #else:\n",
    "    return language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding difference between R language and R&D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffbet_Rlang_RndD(final_words):\n",
    "    r_count=0\n",
    "    rd_count=0\n",
    "    for i in range(len(final_words)):\n",
    "        if(final_words[i]==\"r\"):\n",
    "            r_count=r_count+1\n",
    "            if(i==len(final_words)-1):\n",
    "                break;\n",
    "            elif(final_words[i+1]=='d'):\n",
    "                rd_count=rd_count+1\n",
    "    if(rd_count>0):\n",
    "        if(r_count==rd_count):\n",
    "            final_words.remove(\"r\")\n",
    "    return final_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting list of skills from the list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_skill_list(concluded_words,unique_skill_list):\n",
    "    matching_skills=[]\n",
    "    for i in range(len(concluded_words)):\n",
    "        for j in range(len(unique_skill_list)):\n",
    "            if(concluded_words[i]==unique_skill_list[j]):\n",
    "                matching_skills.append(concluded_words[i])\n",
    "    \n",
    "    matching_skills=set(matching_skills)\n",
    "    matching_skills=list(matching_skills)\n",
    "    return matching_skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the incorrectly mentioned skill and appending the skill list with correct name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_wrong_namings(matching_skills,wrong,correct):\n",
    "    for i in range(len(matching_skills)):\n",
    "        for j in range(len(wrong)):\n",
    "            if(matching_skills[i]==wrong[j]):\n",
    "                matching_skills.remove(wrong[j])\n",
    "                matching_skills.append(correct[j])\n",
    "    \n",
    "    matching_skills=set(matching_skills)\n",
    "    matching_skills=list(matching_skills)\n",
    "    return matching_skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding difference between 'analytics' and different types of analytics like 'data analytics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_skills(matching_skills,corrected_skills,final_analytics):\n",
    "    diff_analytics_count=0\n",
    "    analytics_count=0\n",
    "    for i in range(len(matching_skills)):\n",
    "        if(matching_skills[i]==\"analytics\"):\n",
    "            analytics_count=analytics_count+1\n",
    "        for j in range(len(final_analytics)):\n",
    "            if(matching_skills[i]==final_analytics[j]):\n",
    "                diff_analytics_count=diff_analytics_count+1\n",
    "    if(diff_analytics_count>0):\n",
    "        if(analytics_count==diff_analytics_count):\n",
    "            corrected_skills.remove(\"analytics\")\n",
    "    return corrected_skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concluding informations from job data by calling the above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "#calling the above functions\n",
    "words_job_description=processing(job_description_data)\n",
    "\n",
    "final_analytics_jd=diff_types_analytics(words_job_description)    \n",
    "final_languages_jd=languages(words_job_description)\n",
    "concluded_words_jd=diffbet_Rlang_RndD(words_job_description)\n",
    "\n",
    "matching_skills_jd=matching_skill_list(concluded_words_jd,unique_skill_list)\n",
    "corrected_skills_jd=remove_wrong_namings(matching_skills_jd,wrong,correct)\n",
    "processed_skills_jd=processing_skills(matching_skills_jd,corrected_skills_jd,final_analytics_jd)\n",
    "company_score=3\n",
    "company_score=company_score+len(final_languages_jd)\n",
    "company_score=company_score+len(processed_skills_jd)\n",
    "print(company_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Industry Type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading industries names file\n",
    "names_data=pd.read_csv(\"industries1.csv\")\n",
    "names_dataframe=pd.DataFrame(names_data)\n",
    "one=names_dataframe['one']\n",
    "two=names_dataframe['two']\n",
    "three=names_dataframe['three']\n",
    "four=names_dataframe['four']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Health     Wellness   and    Fitness']\n"
     ]
    }
   ],
   "source": [
    "#making changes in the words which are wrongly displayed\n",
    "#eg.: SoftwareStaffingRecruiting => Software Staffing Recruting\n",
    "ind=[]\n",
    "\n",
    "string=''\n",
    "for j in industry:\n",
    "    if(j==j.lower()):\n",
    "        string=string+j\n",
    "    if(j==j.upper()):\n",
    "        string = string+\" \"+j\n",
    "ind.append(string)\n",
    "\n",
    "for i in range(len(ind)):\n",
    "    if(\"& &\" in ind[i]):\n",
    "        ind[i]=ind[i].replace(\" & \",' ')\n",
    "    if(\", ,\" in ind[i]):\n",
    "        ind[i]=ind[i].replace(\", ,\",' ')\n",
    "    if(\"/\" in ind[i]):\n",
    "        ind[i]=ind[i].replace(\"/\",' ')\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization        \n",
    "for i in range(len(ind)):\n",
    "    test=nltk.word_tokenize(ind[i])\n",
    "\n",
    "    #finds the industry type of the company    \n",
    "    if(len(test)==1):\n",
    "        for l in range(len(one)):\n",
    "            if(test[0]==one[l]):\n",
    "                found_industry=str(test[0]).lower()\n",
    "\n",
    "    elif(len(test)==2):\n",
    "        for l in range(len(one)):\n",
    "            if(test[0]==one[l] and test[1]==two[l]):\n",
    "                found_industry=str(test[0]+' '+test[1]).lower()\n",
    "            elif(test[1]==one[l] and two[l]==' '):\n",
    "                found_industry=str(test[1]).lower()\n",
    "\n",
    "    elif(len(test)==3):\n",
    "        for l in range(len(one)):\n",
    "            if(test[0]==one[l] and test[1]==two[l] and test[2]==three[l]):\n",
    "                found_industry=str(test[0]+' '+test[1]+' '+test[2]).lower()\n",
    "            elif(test[1]==one[l] and test[2]==two[l]):\n",
    "                found_industry=str(test[1]+' '+test[2]).lower()\n",
    "            elif(test[2]==one[l]):\n",
    "                found_industry=str(test[2]).lower()\n",
    "\n",
    "    elif(len(test)==0):\n",
    "        continue;\n",
    "\n",
    "    else:\n",
    "        ind1=[]\n",
    "        for j in range(len(test),len(test)-4,-1):\n",
    "            ind1.append(test[j-1])\n",
    "        ind1=ind1[::-1]\n",
    "        for l in range(len(one)):\n",
    "            if(ind1[0]==one[l] and ind1[1]==two[l] and ind1[2]==three[l] and ind1[3]==four[l]):\n",
    "                found_industry=str(ind1[0]+' '+ind1[1]+' '+ind1[2]+' '+ind1[3]).lower()\n",
    "            elif(ind1[1]==one[l] and ind1[2]==two[l] and ind1[3]==three[l]):\n",
    "                found_industry=str(ind1[1]+' '+ind1[2]+' '+ind1[3]).lower()\n",
    "            elif(ind1[2]==one[l] and ind1[3]==two[l]):\n",
    "                found_industry=str(ind1[2]+' '+ind1[3]).lower()\n",
    "            elif(ind1[3]==one[l]):\n",
    "                found_industry=str(ind1[3]).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outputting informations from the resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID                                                    1.98916e+09\n",
      "Date                                                       18-08-2020\n",
      "Company Name                                                     Zava\n",
      "Post                                                     Data Analyst\n",
      "Location                              London, England, United Kingdom\n",
      "No.of Applicants                                                  105\n",
      "Description         About Zava Weâ€™re an online doctor service and ...\n",
      "Level                                                  Not Applicable\n",
      "Type                                                        Full-time\n",
      "Function                                                      Analyst\n",
      "Industry                                 Health, Wellness and Fitness\n",
      "Link                                                                 \n",
      "Review                                                               \n",
      "Name: 1643, dtype: object\n",
      "\n",
      "Required languages:\n",
      "['french', 'german']\n",
      "\n",
      "Required skills:\n",
      "['python', 'data analytics', 'business intelligence', 'product design', 'ux', 'analytics', 'data interpretation', 'r', 'sql', 'ui']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['manila']\n",
      "Candidate location: manila\n",
      "Distance in km:\n",
      "2020_CV_Ronn_Kevin_Santos.docx : 10735.678852673145\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "2020_CV_Ronn_Kevin_Santos.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Aaditya_CV.docx : 5478.478415221937\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Aaditya_CV.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Abdelrahman-CV-N.docx : 5478.478415221937\n",
      "Languages known : ['arabic']\n",
      "Matching languages : \n",
      "Abdelrahman-CV-N.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Abdullah_Alattar_2020.docx : 5478.478415221937\n",
      "Languages known : ['arabic']\n",
      "Matching languages : \n",
      "Abdullah_Alattar_2020.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['abu dhabi']\n",
      "Candidate location: abu dhabi\n",
      "Distance in km:\n",
      "Abukersh_Jun2020.docx : 5472.345189615449\n",
      "Languages known : ['arabic', 'italian']\n",
      "Matching languages : \n",
      "Abukersh_Jun2020.docx : []\n",
      "Experience level : 0\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "AdityaM.docx : 5478.478415221937\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "AdityaM.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Afra Yaqoob CV.docx : 5478.478415221937\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Afra Yaqoob CV.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Agnel Mamachan CV & Cover Letter.docx : 5478.478415221937\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Agnel Mamachan CV & Cover Letter.docx : []\n",
      "Experience level : 2\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['tripoli']\n",
      "Candidate location: tripoli\n",
      "Distance in km:\n",
      "Ahmed El Chafei Resume.docx : 2333.314074724882\n",
      "Languages known : ['french', 'arabic', 'spanish', 'german', 'dutch', 'italian']\n",
      "Matching languages : \n",
      "Ahmed El Chafei Resume.docx : ['french', 'german']\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['abu dhabi']\n",
      "Candidate location: abu dhabi\n",
      "Distance in km:\n",
      "Ahmed Hassan-CV-Resume-August 2020.docx : 5472.345189615449\n",
      "Languages known : ['arabic']\n",
      "Matching languages : \n",
      "Ahmed Hassan-CV-Resume-August 2020.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['karachi']\n",
      "Candidate location: karachi\n",
      "Distance in km:\n",
      "Ahmed Nurullah_BI and Data Lead.docx : 6298.164499583673\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Ahmed Nurullah_BI and Data Lead.docx : []\n",
      "Experience level : 11\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Ahmed_Abdelkader_CV-2.docx : 5478.478415221937\n",
      "Languages known : ['arabic']\n",
      "Matching languages : \n",
      "Ahmed_Abdelkader_CV-2.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['indianapolis']\n",
      "Candidate location: indianapolis\n",
      "Distance in km:\n",
      "Aizaz CV 2.01 (4).docx : 6420.193387009308\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Aizaz CV 2.01 (4).docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['chennai']\n",
      "Candidate location: chennai\n",
      "Distance in km:\n",
      "ajmal_resume.docx : 8211.97733499229\n",
      "Languages known : ['hindi', 'arabic']\n",
      "Matching languages : \n",
      "ajmal_resume.docx : []\n",
      "Experience level : 12\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['mumbai']\n",
      "Candidate location: mumbai\n",
      "Distance in km:\n",
      "Alia_cv_final.docx : 7200.25174889281\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Alia_cv_final.docx : []\n",
      "Experience level : 18\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Alma-Resume.docx : 5478.478415221937\n",
      "Languages known : ['tamil']\n",
      "Matching languages : \n",
      "Alma-Resume.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['istanbul']\n",
      "Candidate location: istanbul\n",
      "Distance in km:\n",
      "Amine CV-9.docx : 2499.7988198539456\n",
      "Languages known : ['turkish', 'french', 'spanish', 'arabic']\n",
      "Matching languages : \n",
      "Amine CV-9.docx : ['french']\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['madrid']\n",
      "Candidate location: madrid\n",
      "Distance in km:\n",
      "Antonio Bastidas_Resume_Aug20.docx : 1263.414718393201\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Antonio Bastidas_Resume_Aug20.docx : []\n",
      "Experience level : 5\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['hong kong']\n",
      "Candidate location: hong kong\n",
      "Distance in km:\n",
      "Ashley_Choy_CV.docx : 9626.277381457214\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Ashley_Choy_CV.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Atif_Ahmad_CV.docx : 5478.478415221937\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Atif_Ahmad_CV.docx : []\n",
      "Experience level : 20\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['philadelphia']\n",
      "Candidate location: philadelphia\n",
      "Distance in km:\n",
      "Ayesha Cv -.docx : 5699.690886663006\n",
      "Languages known : ['urdu', 'arabic']\n",
      "Matching languages : \n",
      "Ayesha Cv -.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['london']\n",
      "Candidate location: london\n",
      "Distance in km:\n",
      "Bachir Barry Data Science CV.docx : 0.0\n",
      "Languages known : ['french']\n",
      "Matching languages : \n",
      "Bachir Barry Data Science CV.docx : ['french']\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['atlanta']\n",
      "Candidate location: atlanta\n",
      "Distance in km:\n",
      "Balgopal_Sabat CV.docx : 6770.1074696358255\n",
      "Languages known : ['hindi']\n",
      "Matching languages : \n",
      "Balgopal_Sabat CV.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['kano']\n",
      "Candidate location: kano\n",
      "Distance in km:\n",
      "Bamidele Olanrewaju Ajayi-converted.docx : 259.0420608764735\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Bamidele Olanrewaju Ajayi-converted.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['miami']\n",
      "Candidate location: miami\n",
      "Distance in km:\n",
      "Beatriz Manzano CV.docx : 7126.016062776013\n",
      "Languages known : ['spanish']\n",
      "Matching languages : \n",
      "Beatriz Manzano CV.docx : []\n",
      "Experience level : 12\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "BI Developer- Anupam Parti.docx : 5478.478415221937\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "BI Developer- Anupam Parti.docx : []\n",
      "Experience level : 10\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Bushra's Resume.docx : 5478.478415221937\n",
      "Languages known : ['hindi', 'urdu']\n",
      "Matching languages : \n",
      "Bushra's Resume.docx : []\n",
      "Experience level : 5\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['hyderabad']\n",
      "Candidate location: hyderabad\n",
      "Distance in km:\n",
      "CV - DA.docx : 7719.7640521729845\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "CV - DA.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['delhi']\n",
      "Candidate location: delhi\n",
      "Distance in km:\n",
      "CV - Shalaka Kumar (1).docx : 6709.121972691988\n",
      "Languages known : ['hindi', 'french', 'urdu']\n",
      "Matching languages : \n",
      "CV - Shalaka Kumar (1).docx : ['french']\n",
      "Experience level : 2\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['saint petersburg']\n",
      "Candidate location: saint petersburg\n",
      "Distance in km:\n",
      "CV-2020 Mohammed Al Balushi.docx : 2091.23140059856\n",
      "Languages known : ['arabic', 'russian']\n",
      "Matching languages : \n",
      "CV-2020 Mohammed Al Balushi.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['davao']\n",
      "Candidate location: davao\n",
      "Distance in km:\n",
      "CV-John-Richard-Gonzales-n.docx : 11713.00331724515\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "CV-John-Richard-Gonzales-n.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['cairo']\n",
      "Candidate location: cairo\n",
      "Distance in km:\n",
      "CV-Mohamed Salem.docx : 3511.391510253383\n",
      "Languages known : ['arabic', 'german']\n",
      "Matching languages : \n",
      "CV-Mohamed Salem.docx : ['german']\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['lahore']\n",
      "Candidate location: lahore\n",
      "Distance in km:\n",
      "CV_Ammara1.docx : 6282.352078939211\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "CV_Ammara1.docx : []\n",
      "Experience level : 10\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['london']\n",
      "Candidate location: london\n",
      "Distance in km:\n",
      "CV_Mohamed Anvergani_4.docx : 0.0\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "CV_Mohamed Anvergani_4.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "CV_Omar_Daoudi_.docx : 5478.478415221937\n",
      "Languages known : ['arabic']\n",
      "Matching languages : \n",
      "CV_Omar_Daoudi_.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['mysore']\n",
      "Candidate location: mysore\n",
      "Distance in km:\n",
      "CV_Ranimaria.docx : 8027.285349716462\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "CV_Ranimaria.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['enterprise']\n",
      "Candidate location: enterprise\n",
      "Distance in km:\n",
      "Dheemantha Wijesinghe - CV.docx : 7059.359483858228\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Dheemantha Wijesinghe - CV.docx : []\n",
      "Experience level : 3\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "DIALA ALMALIK CV.docx : 5478.478415221937\n",
      "Languages known : ['arabic']\n",
      "Matching languages : \n",
      "DIALA ALMALIK CV.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['mumbai']\n",
      "Candidate location: mumbai\n",
      "Distance in km:\n",
      "DS-2008.docx : 7200.25174889281\n",
      "Languages known : ['hindi']\n",
      "Matching languages : \n",
      "DS-2008.docx : []\n",
      "Experience level : 6\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['paris']\n",
      "Candidate location: paris\n",
      "Distance in km:\n",
      "EA-CV_Sameh_BenFredj_2020.docx : 343.5072691492576\n",
      "Languages known : ['french', 'spanish', 'arabic']\n",
      "Matching languages : \n",
      "EA-CV_Sameh_BenFredj_2020.docx : ['french']\n",
      "Experience level : 6\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['moscow']\n",
      "Candidate location: moscow\n",
      "Distance in km:\n",
      "EA-Resume Anton Dimov.docx : 2500.5982675695764\n",
      "Languages known : ['russian']\n",
      "Matching languages : \n",
      "EA-Resume Anton Dimov.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['san francisco']\n",
      "Candidate location: san francisco\n",
      "Distance in km:\n",
      "Geoffrey Brown.docx : 8616.093762050956\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Geoffrey Brown.docx : []\n",
      "Experience level : 0\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['paris']\n",
      "Candidate location: paris\n",
      "Distance in km:\n",
      "LyanneGibson.docx : 343.5072691492576\n",
      "Languages known : ['french']\n",
      "Matching languages : \n",
      "LyanneGibson.docx : ['french']\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['jaipur']\n",
      "Candidate location: jaipur\n",
      "Distance in km:\n",
      "MallikaCV (1).docx : 6751.861567545736\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "MallikaCV (1).docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['mumbai']\n",
      "Candidate location: mumbai\n",
      "Distance in km:\n",
      "Mandrekar_Isha.docx : 7200.25174889281\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Mandrekar_Isha.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Matt McCarthy - CV.docx : 5478.478415221937\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Matt McCarthy - CV.docx : []\n",
      "Experience level : 0\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "MhdAlaa-CV-Updated-2.docx : 5478.478415221937\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "MhdAlaa-CV-Updated-2.docx : []\n",
      "Experience level : Not mentioned\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['dubai']\n",
      "Candidate location: dubai\n",
      "Distance in km:\n",
      "Reeka Hazarika - Resume.docx : 5478.478415221937\n",
      "Languages known : ['hindi']\n",
      "Matching languages : \n",
      "Reeka Hazarika - Resume.docx : []\n",
      "Experience level : 9\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['lahore']\n",
      "Candidate location: lahore\n",
      "Distance in km:\n",
      "Resume Sajjad Tahir Nov 2019.docx : 6282.352078939211\n",
      "Languages known : []\n",
      "Matching languages : \n",
      "Resume Sajjad Tahir Nov 2019.docx : []\n",
      "Experience level : 9\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['hyderabad']\n",
      "Candidate location: hyderabad\n",
      "Distance in km:\n",
      "Shireen-CV-2020.docx : 7719.7640521729845\n",
      "Languages known : ['hindi', 'arabic', 'telugu']\n",
      "Matching languages : \n",
      "Shireen-CV-2020.docx : []\n",
      "Experience level : 4\n",
      "level matches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#skills and languages are collected from the job description\n",
    "print(single_company_data)\n",
    "print(\"\\nRequired languages:\")\n",
    "print(final_languages_jd)\n",
    "print(\"\\nRequired skills:\")\n",
    "print(processed_skills_jd)\n",
    "print(\"\\n\")\n",
    "\n",
    "score=[]\n",
    "candidate_skills=[]\n",
    "candidate={}\n",
    "a,b,c,p,z=0,0,0,0,0\n",
    "name=[]\n",
    "\n",
    "cities_data=pd.read_csv(\"worldcities.csv\")\n",
    "cities=cities_data['city_ascii']\n",
    "for i in range(len(cities)):\n",
    "    cities[i]=cities[i].lower()\n",
    "#print(cities)\n",
    "\n",
    "#Reading all the resumes from the 'resumes' folder\n",
    "entries = os.listdir('resumes')\n",
    "\n",
    "#for loop for each resume\n",
    "for entry in entries:\n",
    "    \n",
    "    #converts docs file to text\n",
    "    resume_data = docx2txt.process(entry)\n",
    "    \n",
    "    #name of the candidate is appended in the list 'name'\n",
    "    name.append(entry)\n",
    "    \n",
    "    #calling the above functions\n",
    "    words_resume=processing(resume_data)\n",
    "    \n",
    "    final_analytics_resume=diff_types_analytics(words_resume)\n",
    "    final_languages_resume=languages(words_resume)\n",
    "    concluded_words_resume=diffbet_Rlang_RndD(words_resume)        \n",
    "    \n",
    "    matching_skills_resume=matching_skill_list(concluded_words_resume,unique_skill_list)\n",
    "    corrected_skills_resume=remove_wrong_namings(matching_skills_resume,wrong,correct)\n",
    "    processed_skills_resume=processing_skills(matching_skills_resume,corrected_skills_resume,final_analytics_resume)\n",
    "    \n",
    "    #skills are collected from the resume\n",
    "    candidate_skills.append(processed_skills_resume)\n",
    "    candidate[name[a]]=processed_skills_resume\n",
    "    a=a+1\n",
    "    \n",
    "    places2=[]\n",
    "    #location of the candidate\n",
    "    for i in range(len(cities)):\n",
    "        for j in range(len(words_resume)):\n",
    "            if(cities[i]==words_resume[j]):\n",
    "                places2.append(words_resume[j])\n",
    "                print(places2)\n",
    "                if(len(places2)==0):\n",
    "                    print(\"goto\")\n",
    "                    continue;\n",
    "                else:\n",
    "                    break;\n",
    "                break;\n",
    "            else: \n",
    "                continue; \n",
    "            break;\n",
    "        else: \n",
    "            continue; \n",
    "        break;\n",
    "    candidate_location=places2[0]\n",
    "    candidate_location=str(candidate_location)\n",
    "    print(\"Candidate location:\",candidate_location)\n",
    "    \n",
    "    places=[]\n",
    "    places.append(company_location)\n",
    "    places.append(candidate_location)\n",
    "    latitude=[]\n",
    "    longitude=[]\n",
    "      \n",
    "    #finding the distance between the candidate location and the company's location\n",
    "    geolocator = Nominatim(user_agent=\"http\")\n",
    "    for i in range(len(places)):\n",
    "        locate = geolocator.geocode(places[i])\n",
    "        latitude.append(locate.latitude)\n",
    "        longitude.append(locate.longitude)\n",
    "           \n",
    "    first = (latitude[0], longitude[0])\n",
    "    second = (latitude[1], longitude[1])\n",
    "    print(\"Distance in km:\")\n",
    "    print(name[b],\":\",great_circle(first, second).km)\n",
    "    scores=0\n",
    "    if(int(great_circle(first, second).km)<=50):\n",
    "        scores=scores+1\n",
    "    elif(int(great_circle(first, second).km)>50):\n",
    "        scores=scores\n",
    "    score.append(scores)\n",
    "    b=b+1   \n",
    "    \n",
    "    #collects the languages known by the candidate\n",
    "    #if(len(final_languages_resume)==0):\n",
    "    #    print(\"No languages mentioned\")\n",
    "    #else:\n",
    "    print(\"Languages known :\",final_languages_resume)    \n",
    "    \n",
    "    #finds the matching languages with the job description and the candidate's resume\n",
    "    matching_languages=[]\n",
    "    for i in range(len(final_languages_jd)):\n",
    "        for j in range(len(final_languages_resume)):\n",
    "            if(final_languages_jd[i]==final_languages_resume[j]):\n",
    "                matching_languages.append(final_languages_jd[i])\n",
    "    print(\"Matching languages : \")\n",
    "    print(name[c],\":\",matching_languages)\n",
    "    score[c]=score[c]+len(matching_languages)\n",
    "    c=c+1\n",
    "    \n",
    "    #industry type matching\n",
    "    industry_score=0\n",
    "    for i in range(len(words_resume)):\n",
    "        if(words_resume[i]==found_industry):\n",
    "            industry_score=industry_score+1\n",
    "        else:\n",
    "            industry_score=industry_score\n",
    "    if(industry_score>=1):\n",
    "        score[z]=score[z]+1\n",
    "    else:\n",
    "        score[z]=score[z]\n",
    "    z=z+1\n",
    "    \n",
    "    \n",
    "    #level of experience matching\n",
    "    years=[]\n",
    "    for j in range(len(words_resume)):\n",
    "        if(words_resume[j]=='years'):\n",
    "            try:\n",
    "                years.append(int(words_resume[j-1]))\n",
    "            except:\n",
    "                years.append(0)\n",
    "                \n",
    "    years1=[]\n",
    "    \n",
    "    if(len(years)>0):\n",
    "        for y in range(len(years)):\n",
    "            if(years[y]<=20):\n",
    "                years1.append(years[y])\n",
    "        \n",
    "        if(len(years1)>0):           \n",
    "            maxx=years1[0]\n",
    "            for i in range(0, len(years1)):        \n",
    "                if(years1[i] > maxx):    \n",
    "                    maxx = years1[i]; \n",
    "            #year = sum(filter(lambda m: isinstance(m, int), years))\n",
    "            year=maxx\n",
    "            #year=int(''.join(list(filter(lambda c: c.isdigit(), year))))\n",
    "            print(\"Experience level :\",year)\n",
    "\n",
    "        else:\n",
    "            year=0\n",
    "            print(\"Experience level : Not mentioned\")\n",
    "    else:\n",
    "        year=0\n",
    "        print(\"Experience level : Not mentioned\")\n",
    "        \n",
    "    \n",
    "    # Job position's needed level        candidate's years of experience  \n",
    "    #-------------------------------------------------------------------\n",
    "    # Not Applicable                =>   greater than or equal to 0\n",
    "    # Entry level or Associate      =>   greater than or equal to 0\n",
    "    # Mid-Senior level              =>   greater than 3\n",
    "    # Executive                     =>   greater than 5\n",
    "    # Director                      =>   greater than 7\n",
    "    \n",
    "    if(type(level)==str):\n",
    "        if(level==\"Not Applicable\"):\n",
    "            if(year>=0):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "\n",
    "        elif(level==\"Entry level\" or level==\"Associate\"):\n",
    "            if(3>year>=0):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "            else:\n",
    "                print(\"level does not match\")\n",
    "                level_score=0\n",
    "\n",
    "        elif(level==\"Mid-Senior level\"):\n",
    "            if(5>=year>=3):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "            else:\n",
    "                print(\"level does not match\")\n",
    "                level_score=0\n",
    "\n",
    "        elif(level==\"Executive\"):\n",
    "            if(7>=year>=5):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "            else:\n",
    "                print(\"level does not match\")  \n",
    "                level_score=0\n",
    "\n",
    "        elif(level==\"Director\"):\n",
    "            if(year>=7):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "            else:\n",
    "                print(\"level does not match\") \n",
    "                level_score=0\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    elif(type(level)==int):\n",
    "        if(level==' '):\n",
    "            if(year>=0):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "\n",
    "        elif(3>int(level)>=0):\n",
    "            if(3>year>=0):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "            else:\n",
    "                print(\"level does not match\")\n",
    "                level_score=0\n",
    "\n",
    "        elif(5>=int(level)>=3):\n",
    "            if(5>=year>=3):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "            else:\n",
    "                print(\"level does not match\")\n",
    "                level_score=0\n",
    "\n",
    "        elif(7>=int(level)>=5):\n",
    "            if(7>=year>=5):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "            else:\n",
    "                print(\"level does not match\")  \n",
    "                level_score=0\n",
    "\n",
    "        elif(int(level)>=7):\n",
    "            if(year>=7):\n",
    "                print(\"level matches\")\n",
    "                level_score=1\n",
    "            else:\n",
    "                print(\"level does not match\") \n",
    "                level_score=0\n",
    "    score[p]=score[p]+level_score\n",
    "    p=p+1\n",
    "    print(\"\\n\")\n",
    "print(score)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching skills with the job description and the candidate's resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final ranking : \n",
      "\n",
      "2020_CV_Ronn_Kevin_Santos.docx  :  3\n",
      "Aaditya_CV.docx  :  3\n",
      "Abdelrahman-CV-N.docx  :  2\n",
      "Abdullah_Alattar_2020.docx  :  2\n",
      "Abukersh_Jun2020.docx  :  4\n",
      "AdityaM.docx  :  2\n",
      "Afra Yaqoob CV.docx  :  2\n",
      "Agnel Mamachan CV & Cover Letter.docx  :  4\n",
      "Ahmed El Chafei Resume.docx  :  0\n",
      "Ahmed Hassan-CV-Resume-August 2020.docx  :  3\n",
      "Ahmed Nurullah_BI and Data Lead.docx  :  4\n",
      "Ahmed_Abdelkader_CV-2.docx  :  0\n",
      "Aizaz CV 2.01 (4).docx  :  2\n",
      "ajmal_resume.docx  :  3\n",
      "Alia_cv_final.docx  :  1\n",
      "Alma-Resume.docx  :  3\n",
      "Amine CV-9.docx  :  2\n",
      "Antonio Bastidas_Resume_Aug20.docx  :  6\n",
      "Ashley_Choy_CV.docx  :  4\n",
      "Atif_Ahmad_CV.docx  :  6\n",
      "Ayesha Cv -.docx  :  3\n",
      "Bachir Barry Data Science CV.docx  :  4\n",
      "Balgopal_Sabat CV.docx  :  4\n",
      "Bamidele Olanrewaju Ajayi-converted.docx  :  0\n",
      "Beatriz Manzano CV.docx  :  4\n",
      "BI Developer- Anupam Parti.docx  :  4\n",
      "Bushra's Resume.docx  :  3\n",
      "CV - DA.docx  :  5\n",
      "CV - Shalaka Kumar (1).docx  :  2\n",
      "CV-2020 Mohammed Al Balushi.docx  :  1\n",
      "CV-John-Richard-Gonzales-n.docx  :  2\n",
      "CV-Mohamed Salem.docx  :  1\n",
      "CV_Ammara1.docx  :  3\n",
      "CV_Mohamed Anvergani_4.docx  :  3\n",
      "CV_Omar_Daoudi_.docx  :  3\n",
      "CV_Ranimaria.docx  :  4\n",
      "Dheemantha Wijesinghe - CV.docx  :  2\n",
      "DIALA ALMALIK CV.docx  :  3\n",
      "DS-2008.docx  :  3\n",
      "EA-CV_Sameh_BenFredj_2020.docx  :  5\n",
      "EA-Resume Anton Dimov.docx  :  1\n",
      "Geoffrey Brown.docx  :  2\n",
      "LyanneGibson.docx  :  4\n",
      "MallikaCV (1).docx  :  7\n",
      "Mandrekar_Isha.docx  :  3\n",
      "Matt McCarthy - CV.docx  :  4\n",
      "MhdAlaa-CV-Updated-2.docx  :  2\n",
      "Reeka Hazarika - Resume.docx  :  4\n",
      "Resume Sajjad Tahir Nov 2019.docx  :  3\n",
      "Shireen-CV-2020.docx  :  5\n",
      "\n",
      "Matching skills : \n",
      "\n",
      "2020_CV_Ronn_Kevin_Santos.docx  :  {'python', 'sql', 'data analytics'}\n",
      "Aaditya_CV.docx  :  {'r', 'python', 'data analytics'}\n",
      "Abdelrahman-CV-N.docx  :  {'python', 'data analytics'}\n",
      "Abdullah_Alattar_2020.docx  :  {'python', 'data analytics'}\n",
      "Abukersh_Jun2020.docx  :  {'ux', 'analytics', 'data analytics', 'ui'}\n",
      "AdityaM.docx  :  {'python', 'data analytics'}\n",
      "Afra Yaqoob CV.docx  :  {'python', 'sql'}\n",
      "Agnel Mamachan CV & Cover Letter.docx  :  {'analytics', 'python', 'sql', 'data analytics'}\n",
      "Ahmed El Chafei Resume.docx  :  set()\n",
      "Ahmed Hassan-CV-Resume-August 2020.docx  :  {'r', 'python', 'data analytics'}\n",
      "Ahmed Nurullah_BI and Data Lead.docx  :  {'python', 'business intelligence', 'sql', 'data analytics'}\n",
      "Ahmed_Abdelkader_CV-2.docx  :  set()\n",
      "Aizaz CV 2.01 (4).docx  :  {'analytics', 'sql'}\n",
      "ajmal_resume.docx  :  {'analytics', 'sql', 'data analytics'}\n",
      "Alia_cv_final.docx  :  {'analytics'}\n",
      "Alma-Resume.docx  :  {'python', 'sql', 'data analytics'}\n",
      "Amine CV-9.docx  :  {'python', 'data analytics'}\n",
      "Antonio Bastidas_Resume_Aug20.docx  :  {'python', 'data analytics', 'business intelligence', 'analytics', 'r', 'sql'}\n",
      "Ashley_Choy_CV.docx  :  {'analytics', 'python', 'sql', 'data analytics'}\n",
      "Atif_Ahmad_CV.docx  :  {'python', 'data analytics', 'business intelligence', 'analytics', 'r', 'sql'}\n",
      "Ayesha Cv -.docx  :  {'r', 'python', 'sql'}\n",
      "Bachir Barry Data Science CV.docx  :  {'r', 'analytics', 'python', 'data analytics'}\n",
      "Balgopal_Sabat CV.docx  :  {'r', 'python', 'sql', 'data analytics'}\n",
      "Bamidele Olanrewaju Ajayi-converted.docx  :  set()\n",
      "Beatriz Manzano CV.docx  :  {'analytics', 'business intelligence', 'data interpretation', 'data analytics'}\n",
      "BI Developer- Anupam Parti.docx  :  {'python', 'business intelligence', 'sql', 'data analytics'}\n",
      "Bushra's Resume.docx  :  {'analytics', 'python', 'sql'}\n",
      "CV - DA.docx  :  {'python', 'data analytics', 'business intelligence', 'analytics', 'sql'}\n",
      "CV - Shalaka Kumar (1).docx  :  {'r', 'data analytics'}\n",
      "CV-2020 Mohammed Al Balushi.docx  :  {'ux'}\n",
      "CV-John-Richard-Gonzales-n.docx  :  {'r', 'data analytics'}\n",
      "CV-Mohamed Salem.docx  :  {'r'}\n",
      "CV_Ammara1.docx  :  {'python', 'sql', 'data analytics'}\n",
      "CV_Mohamed Anvergani_4.docx  :  {'analytics', 'sql', 'data analytics'}\n",
      "CV_Omar_Daoudi_.docx  :  {'r', 'python', 'sql'}\n",
      "CV_Ranimaria.docx  :  {'r', 'analytics', 'sql', 'data analytics'}\n",
      "Dheemantha Wijesinghe - CV.docx  :  {'analytics', 'data analytics'}\n",
      "DIALA ALMALIK CV.docx  :  {'r', 'analytics', 'data analytics'}\n",
      "DS-2008.docx  :  {'python', 'sql', 'data analytics'}\n",
      "EA-CV_Sameh_BenFredj_2020.docx  :  {'python', 'data analytics', 'analytics', 'r', 'sql'}\n",
      "EA-Resume Anton Dimov.docx  :  {'data analytics'}\n",
      "Geoffrey Brown.docx  :  {'python', 'data analytics'}\n",
      "LyanneGibson.docx  :  {'r', 'python', 'sql', 'data analytics'}\n",
      "MallikaCV (1).docx  :  {'python', 'data analytics', 'business intelligence', 'analytics', 'data interpretation', 'r', 'sql'}\n",
      "Mandrekar_Isha.docx  :  {'python', 'sql', 'data analytics'}\n",
      "Matt McCarthy - CV.docx  :  {'r', 'python', 'sql', 'data analytics'}\n",
      "MhdAlaa-CV-Updated-2.docx  :  {'python', 'sql'}\n",
      "Reeka Hazarika - Resume.docx  :  {'r', 'python', 'sql', 'data analytics'}\n",
      "Resume Sajjad Tahir Nov 2019.docx  :  {'analytics', 'business intelligence', 'data analytics'}\n",
      "Shireen-CV-2020.docx  :  {'python', 'data analytics', 'business intelligence', 'analytics', 'sql'}\n",
      "[4, 4, 3, 3, 5, 3, 3, 5, 3, 4, 5, 1, 3, 4, 2, 4, 4, 7, 5, 7, 4, 7, 5, 1, 5, 5, 4, 6, 4, 2, 3, 3, 4, 5, 4, 5, 3, 4, 4, 7, 2, 3, 6, 8, 4, 5, 3, 5, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "final_rank={}\n",
    "matching={}\n",
    "def fun(candidate,comp,st_n):\n",
    "\n",
    "    set1=set(candidate)\n",
    "    set2=set(comp)\n",
    "    \n",
    "    set3=set1.intersection(set2)\n",
    "    \n",
    "    final_rank.update({st_n:len(set3)})\n",
    "\n",
    "    matching.update({st_n:set3})\n",
    "    \n",
    "for i,j in candidate.items():\n",
    "    fun(processed_skills_jd,j,i)\n",
    "     \n",
    "#Final ranking tells the count of the matching skills \n",
    "#print(\"\\nFinal ranking : \" ,final_rank)\n",
    "print(\"Final ranking : \\n\")\n",
    "i=0\n",
    "for key, value in final_rank.items():\n",
    "    print(key, ' : ', value)\n",
    "    score[i]=score[i]+value\n",
    "    i=i+1\n",
    "\n",
    "#Matching skills\n",
    "#print('Matching skills : ' , matching)\n",
    "print('\\nMatching skills : \\n')\n",
    "for key1, value1 in matching.items():\n",
    "    print(key1, ' : ', value1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1=[]\n",
    "for key1, value1 in matching.items():\n",
    "    names1.append(key1)\n",
    "#print(names1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MallikaCV (1).docx': 8, 'Antonio Bastidas_Resume_Aug20.docx': 7, 'Atif_Ahmad_CV.docx': 7, 'Bachir Barry Data Science CV.docx': 7, 'EA-CV_Sameh_BenFredj_2020.docx': 7, 'CV - DA.docx': 6, 'LyanneGibson.docx': 6, 'Shireen-CV-2020.docx': 6, 'Abukersh_Jun2020.docx': 5, 'Agnel Mamachan CV & Cover Letter.docx': 5, 'Ahmed Nurullah_BI and Data Lead.docx': 5, 'Ashley_Choy_CV.docx': 5, 'Balgopal_Sabat CV.docx': 5, 'Beatriz Manzano CV.docx': 5, 'BI Developer- Anupam Parti.docx': 5, 'CV_Mohamed Anvergani_4.docx': 5, 'CV_Ranimaria.docx': 5, 'Matt McCarthy - CV.docx': 5, 'Reeka Hazarika - Resume.docx': 5, '2020_CV_Ronn_Kevin_Santos.docx': 4, 'Aaditya_CV.docx': 4, 'Ahmed Hassan-CV-Resume-August 2020.docx': 4, 'ajmal_resume.docx': 4, 'Alma-Resume.docx': 4, 'Amine CV-9.docx': 4, 'Ayesha Cv -.docx': 4, \"Bushra's Resume.docx\": 4, 'CV - Shalaka Kumar (1).docx': 4, 'CV_Ammara1.docx': 4, 'CV_Omar_Daoudi_.docx': 4, 'DIALA ALMALIK CV.docx': 4, 'DS-2008.docx': 4, 'Mandrekar_Isha.docx': 4, 'Resume Sajjad Tahir Nov 2019.docx': 4, 'Abdelrahman-CV-N.docx': 3, 'Abdullah_Alattar_2020.docx': 3, 'AdityaM.docx': 3, 'Afra Yaqoob CV.docx': 3, 'Ahmed El Chafei Resume.docx': 3, 'Aizaz CV 2.01 (4).docx': 3, 'CV-John-Richard-Gonzales-n.docx': 3, 'CV-Mohamed Salem.docx': 3, 'Dheemantha Wijesinghe - CV.docx': 3, 'Geoffrey Brown.docx': 3, 'MhdAlaa-CV-Updated-2.docx': 3, 'Alia_cv_final.docx': 2, 'CV-2020 Mohammed Al Balushi.docx': 2, 'EA-Resume Anton Dimov.docx': 2, 'Ahmed_Abdelkader_CV-2.docx': 1, 'Bamidele Olanrewaju Ajayi-converted.docx': 1}\n"
     ]
    }
   ],
   "source": [
    "# to convert lists to dictionary \n",
    "res = {} \n",
    "for key in names1: \n",
    "    for value in score: \n",
    "        res[key] = value \n",
    "        score.remove(value) \n",
    "        break    \n",
    "#print (\"Resultant dictionary is : \" +  str(res))\n",
    "\n",
    "import operator\n",
    "sorted_d = dict(sorted(res.items(), key=operator.itemgetter(1),reverse=True))\n",
    "print(sorted_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "names2=[]\n",
    "scores2=[]\n",
    "for key1, value1 in sorted_d.items():\n",
    "    names2.append(key1)\n",
    "    scores2.append(value1)\n",
    "#print(names2)\n",
    "#print(scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies2=[]\n",
    "companies2.append(title)\n",
    "companies2.append(1645)\n",
    "for i in range(len(scores2)-2):\n",
    "    companies2.append(' ')\n",
    "#print(companies2)\n",
    "\n",
    "properties2=[]\n",
    "properties2.append(company_score)\n",
    "for i in range(len(scores2)-1):\n",
    "    properties2.append(' ')\n",
    "#print(properties2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes3=pd.DataFrame({'Company':companies2,\n",
    "                      'Property':properties2,\n",
    "                      'Names':names2,\n",
    "                      'Score':scores2})\n",
    "      \n",
    "#storing in csv file\n",
    "resumes3.to_csv(\"Output.csv\", mode='a', header=False, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
